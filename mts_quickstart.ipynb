{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mts_quickstart.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOu2HXUL5qWwYwKBnSPVots",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangcongcong123/mts/blob/master/mts_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsuYPq9mdonl",
        "colab_type": "text"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdQm5ZvdcUam",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "c42c077e-94e6-44a9-c192-92dc71869e7c"
      },
      "source": [
        "!git clone https://github.com/wangcongcong123/mts.git\n",
        "%cd mts"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mts'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 55 (delta 11), reused 44 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (55/55), done.\n",
            "/content/mts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BheSv8aQdrZl",
        "colab_type": "text"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFPgkL2qcZpW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "outputId": "2ad5bafb-9285-41c0-f01a-c367e677b90c"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.22.2.post1)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.6.0+cu101)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.0.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->-r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (3.12.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.7.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.31.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.34.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (49.2.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.17.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 5)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 3)) (1.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c66J5hqMdwXH",
        "colab_type": "text"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NiL4dVjc3zx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9f2521a5-414b-4110-caf8-8efa43e34c63"
      },
      "source": [
        "!python obtain_split_data.py --dataset_name iris --test_size 0.1 "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numeric_feature_names:\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "done writing iris to data/iris\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFL6j6bid2EI",
        "colab_type": "text"
      },
      "source": [
        "## Train and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrL5bpQtc_5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e9c56f44-e526-4dd7-826b-2ca1ad657b05"
      },
      "source": [
        "!python run.py --dataset_name iris --task cls --train_epochs 100 --train_batch_size 130 --device cpu --lr 0.03 --do_train --do_eval"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 48/100 iter 0: train loss 0.14703. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 48/100 iter 1: train loss 0.02886. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 48, global step: 96] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.84      0.91        49\n",
            "           2       0.85      1.00      0.92        44\n",
            "\n",
            "    accuracy                           0.94       135\n",
            "   macro avg       0.95      0.95      0.94       135\n",
            "weighted avg       0.95      0.94      0.94       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9407407407407408,\n",
            "  \"train_loss\": 0.08794476371258497\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1098.56it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 48, global step: 96] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.08211137354373932,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 28\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_90\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_96\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_96\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_96\n",
            "training epoch 48/100 iter 1: train loss 0.02886. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 96.81it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 48, global step: 97] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.84      0.91        49\n",
            "           2       0.85      1.00      0.92        44\n",
            "\n",
            "    accuracy                           0.94       135\n",
            "   macro avg       0.95      0.95      0.94       135\n",
            "weighted avg       0.95      0.94      0.94       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9407407407407408,\n",
            "  \"train_loss\": 0.08794476371258497\n",
            "}\n",
            "INFO:trainer:start training epoch 49\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 49/100 iter 0: train loss 0.09998. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 49/100 iter 1: train loss 0.04821. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 49, global step: 98] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.96      0.98        49\n",
            "           2       0.96      1.00      0.98        44\n",
            "\n",
            "    accuracy                           0.99       135\n",
            "   macro avg       0.99      0.99      0.99       135\n",
            "weighted avg       0.99      0.99      0.99       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9851851851851852,\n",
            "  \"train_loss\": 0.07409724034368992\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1094.55it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 49, global step: 98] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.30597084760665894,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 29\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_92\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_98\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_98\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_98\n",
            "training epoch 49/100 iter 1: train loss 0.04821. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 97.56it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 49, global step: 99] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.96      0.98        49\n",
            "           2       0.96      1.00      0.98        44\n",
            "\n",
            "    accuracy                           0.99       135\n",
            "   macro avg       0.99      0.99      0.99       135\n",
            "weighted avg       0.99      0.99      0.99       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9851851851851852,\n",
            "  \"train_loss\": 0.07409724034368992\n",
            "}\n",
            " 49% 49/100 [00:01<00:01, 37.63it/s]INFO:trainer:start training epoch 50\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 50/100 iter 0: train loss 0.24385. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 50/100 iter 1: train loss 0.10994. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 50, global step: 100] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.83      0.98      0.90        49\n",
            "           2       0.97      0.77      0.86        44\n",
            "\n",
            "    accuracy                           0.92       135\n",
            "   macro avg       0.93      0.92      0.92       135\n",
            "weighted avg       0.93      0.92      0.92       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9185185185185185,\n",
            "  \"train_loss\": 0.17689590901136398\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1189.20it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 50, global step: 100] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.08473911881446838,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 30\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_94\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_100\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_100\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_100\n",
            "training epoch 50/100 iter 1: train loss 0.10994. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 93.53it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 50, global step: 101] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.83      0.98      0.90        49\n",
            "           2       0.97      0.77      0.86        44\n",
            "\n",
            "    accuracy                           0.92       135\n",
            "   macro avg       0.93      0.92      0.92       135\n",
            "weighted avg       0.93      0.92      0.92       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9185185185185185,\n",
            "  \"train_loss\": 0.17689590901136398\n",
            "}\n",
            "INFO:trainer:start training epoch 51\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 51/100 iter 0: train loss 0.08179. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 51/100 iter 1: train loss 0.00341. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 51, global step: 102] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.96      0.97        49\n",
            "           2       0.96      0.98      0.97        44\n",
            "\n",
            "    accuracy                           0.98       135\n",
            "   macro avg       0.98      0.98      0.98       135\n",
            "weighted avg       0.98      0.98      0.98       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9777777777777777,\n",
            "  \"train_loss\": 0.04259909165557474\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1042.06it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 51, global step: 102] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.022802066057920456,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 31\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_96\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_102\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_102\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_102\n",
            "training epoch 51/100 iter 1: train loss 0.00341. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 90.62it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 51, global step: 103] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.96      0.97        49\n",
            "           2       0.96      0.98      0.97        44\n",
            "\n",
            "    accuracy                           0.98       135\n",
            "   macro avg       0.98      0.98      0.98       135\n",
            "weighted avg       0.98      0.98      0.98       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9777777777777777,\n",
            "  \"train_loss\": 0.04259909165557474\n",
            "}\n",
            "INFO:trainer:start training epoch 52\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 52/100 iter 0: train loss 0.08807. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 52/100 iter 1: train loss 0.32857. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 52, global step: 104] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.88      0.93        49\n",
            "           2       0.88      1.00      0.94        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.96      0.96      0.96       135\n",
            "weighted avg       0.96      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9555555555555556,\n",
            "  \"train_loss\": 0.20831705257296562\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1145.05it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 52, global step: 104] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.018543925136327744,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 32\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_98\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_104\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_104\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_104\n",
            "training epoch 52/100 iter 1: train loss 0.32857. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 97.53it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 52, global step: 105] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.88      0.93        49\n",
            "           2       0.88      1.00      0.94        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.96      0.96      0.96       135\n",
            "weighted avg       0.96      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9555555555555556,\n",
            "  \"train_loss\": 0.20831705257296562\n",
            "}\n",
            "INFO:trainer:start training epoch 53\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 53/100 iter 0: train loss 0.09813. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 53/100 iter 1: train loss 0.00229. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 53, global step: 106] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.88      0.93        49\n",
            "           2       0.88      1.00      0.94        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.96      0.96      0.96       135\n",
            "weighted avg       0.96      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9555555555555556,\n",
            "  \"train_loss\": 0.050210822257213295\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1157.05it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 53, global step: 106] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.042096398770809174,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 33\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_100\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_106\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_106\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_106\n",
            "training epoch 53/100 iter 1: train loss 0.00229. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 99.27it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 53, global step: 107] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.88      0.93        49\n",
            "           2       0.88      1.00      0.94        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.96      0.96      0.96       135\n",
            "weighted avg       0.96      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9555555555555556,\n",
            "  \"train_loss\": 0.050210822257213295\n",
            "}\n",
            " 53% 53/100 [00:01<00:01, 38.00it/s]INFO:trainer:start training epoch 54\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 54/100 iter 0: train loss 0.06265. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 54/100 iter 1: train loss 0.00732. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 54, global step: 108] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.96      0.97        49\n",
            "           2       0.96      0.98      0.97        44\n",
            "\n",
            "    accuracy                           0.98       135\n",
            "   macro avg       0.98      0.98      0.98       135\n",
            "weighted avg       0.98      0.98      0.98       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9777777777777777,\n",
            "  \"train_loss\": 0.03498464520089328\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1143.17it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 54, global step: 108] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.2036510407924652,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 34\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_102\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_108\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_108\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_108\n",
            "training epoch 54/100 iter 1: train loss 0.00732. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 96.33it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 54, global step: 109] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.96      0.97        49\n",
            "           2       0.96      0.98      0.97        44\n",
            "\n",
            "    accuracy                           0.98       135\n",
            "   macro avg       0.98      0.98      0.98       135\n",
            "weighted avg       0.98      0.98      0.98       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9777777777777777,\n",
            "  \"train_loss\": 0.03498464520089328\n",
            "}\n",
            "INFO:trainer:start training epoch 55\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 55/100 iter 0: train loss 0.15685. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 55/100 iter 1: train loss 0.00277. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 55, global step: 110] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.87      0.98      0.92        49\n",
            "           2       0.97      0.84      0.90        44\n",
            "\n",
            "    accuracy                           0.94       135\n",
            "   macro avg       0.95      0.94      0.94       135\n",
            "weighted avg       0.95      0.94      0.94       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9407407407407408,\n",
            "  \"train_loss\": 0.07981213391758502\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 467.23it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 55, global step: 110] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.050941143184900284,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 35\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_104\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_110\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_110\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_110\n",
            "training epoch 55/100 iter 1: train loss 0.00277. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 78.41it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 55, global step: 111] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.87      0.98      0.92        49\n",
            "           2       0.97      0.84      0.90        44\n",
            "\n",
            "    accuracy                           0.94       135\n",
            "   macro avg       0.95      0.94      0.94       135\n",
            "weighted avg       0.95      0.94      0.94       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9407407407407408,\n",
            "  \"train_loss\": 0.07981213391758502\n",
            "}\n",
            "INFO:trainer:start training epoch 56\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 56/100 iter 0: train loss 0.04635. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 56/100 iter 1: train loss 0.55159. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 56, global step: 112] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.96      0.97        49\n",
            "           2       0.96      0.98      0.97        44\n",
            "\n",
            "    accuracy                           0.98       135\n",
            "   macro avg       0.98      0.98      0.98       135\n",
            "weighted avg       0.98      0.98      0.98       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9777777777777777,\n",
            "  \"train_loss\": 0.2989700734615326\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1053.32it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 56, global step: 112] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.041385870426893234,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 36\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_106\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_112\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_112\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_112\n",
            "training epoch 56/100 iter 1: train loss 0.55159. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 96.99it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 56, global step: 113] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.96      0.97        49\n",
            "           2       0.96      0.98      0.97        44\n",
            "\n",
            "    accuracy                           0.98       135\n",
            "   macro avg       0.98      0.98      0.98       135\n",
            "weighted avg       0.98      0.98      0.98       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9777777777777777,\n",
            "  \"train_loss\": 0.2989700734615326\n",
            "}\n",
            "INFO:trainer:start training epoch 57\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 57/100 iter 0: train loss 0.05764. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 57/100 iter 1: train loss 0.22363. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 57, global step: 114] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.96      0.97        49\n",
            "           2       0.96      0.98      0.97        44\n",
            "\n",
            "    accuracy                           0.98       135\n",
            "   macro avg       0.98      0.98      0.98       135\n",
            "weighted avg       0.98      0.98      0.98       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9777777777777777,\n",
            "  \"train_loss\": 0.1406347118318081\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1180.50it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 57, global step: 114] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.026621302589774132,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 37\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_108\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_114\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_114\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_114\n",
            "training epoch 57/100 iter 1: train loss 0.22363. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 90.09it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 57, global step: 115] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.96      0.97        49\n",
            "           2       0.96      0.98      0.97        44\n",
            "\n",
            "    accuracy                           0.98       135\n",
            "   macro avg       0.98      0.98      0.98       135\n",
            "weighted avg       0.98      0.98      0.98       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9777777777777777,\n",
            "  \"train_loss\": 0.1406347118318081\n",
            "}\n",
            " 57% 57/100 [00:01<00:01, 37.90it/s]INFO:trainer:start training epoch 58\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 58/100 iter 0: train loss 0.08620. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 58/100 iter 1: train loss 0.57079. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 58, global step: 116] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.88      0.93        49\n",
            "           2       0.88      1.00      0.94        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.96      0.96      0.96       135\n",
            "weighted avg       0.96      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9555555555555556,\n",
            "  \"train_loss\": 0.3284943178296089\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 818.72it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.62      0.67      0.64        15\n",
            "weighted avg       0.88      0.93      0.90        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 58, global step: 116] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.62      0.67      0.64        15\n",
            "weighted avg       0.88      0.93      0.90        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.08582594990730286,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 38\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_110\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_116\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_116\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_116\n",
            "training epoch 58/100 iter 1: train loss 0.57079. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 86.14it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 58, global step: 117] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.88      0.93        49\n",
            "           2       0.88      1.00      0.94        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.96      0.96      0.96       135\n",
            "weighted avg       0.96      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9555555555555556,\n",
            "  \"train_loss\": 0.3284943178296089\n",
            "}\n",
            "INFO:trainer:start training epoch 59\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 59/100 iter 0: train loss 0.25037. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 59/100 iter 1: train loss 0.01140. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 59, global step: 118] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.65      0.79        49\n",
            "           2       0.72      1.00      0.84        44\n",
            "\n",
            "    accuracy                           0.87       135\n",
            "   macro avg       0.91      0.88      0.88       135\n",
            "weighted avg       0.91      0.87      0.87       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.8740740740740741,\n",
            "  \"train_loss\": 0.13088371139019728\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1089.15it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.62      0.67      0.64        15\n",
            "weighted avg       0.88      0.93      0.90        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 59, global step: 118] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.62      0.67      0.64        15\n",
            "weighted avg       0.88      0.93      0.90        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.06956393271684647,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 39\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_112\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_118\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_118\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_118\n",
            "training epoch 59/100 iter 1: train loss 0.01140. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 90.50it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 59, global step: 119] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.65      0.79        49\n",
            "           2       0.72      1.00      0.84        44\n",
            "\n",
            "    accuracy                           0.87       135\n",
            "   macro avg       0.91      0.88      0.88       135\n",
            "weighted avg       0.91      0.87      0.87       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.8740740740740741,\n",
            "  \"train_loss\": 0.13088371139019728\n",
            "}\n",
            "INFO:trainer:start training epoch 60\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 60/100 iter 0: train loss 0.17791. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 60/100 iter 1: train loss 0.02959. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 60, global step: 120] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.76      0.86        49\n",
            "           2       0.79      1.00      0.88        44\n",
            "\n",
            "    accuracy                           0.91       135\n",
            "   macro avg       0.93      0.92      0.91       135\n",
            "weighted avg       0.93      0.91      0.91       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9111111111111111,\n",
            "  \"train_loss\": 0.10375046916306019\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1146.92it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 60, global step: 120] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.07677377015352249,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 40\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_114\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_120\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_120\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_120\n",
            "training epoch 60/100 iter 1: train loss 0.02959. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 98.42it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 60, global step: 121] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.76      0.86        49\n",
            "           2       0.79      1.00      0.88        44\n",
            "\n",
            "    accuracy                           0.91       135\n",
            "   macro avg       0.93      0.92      0.91       135\n",
            "weighted avg       0.93      0.91      0.91       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9111111111111111,\n",
            "  \"train_loss\": 0.10375046916306019\n",
            "}\n",
            "INFO:trainer:start training epoch 61\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 61/100 iter 0: train loss 0.12273. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 61/100 iter 1: train loss 0.07247. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 61, global step: 122] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.88      0.93        49\n",
            "           2       0.88      1.00      0.94        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.96      0.96      0.96       135\n",
            "weighted avg       0.96      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9555555555555556,\n",
            "  \"train_loss\": 0.09760033711791039\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1042.32it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 61, global step: 122] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.10580316931009293,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 41\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_116\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_122\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_122\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_122\n",
            "training epoch 61/100 iter 1: train loss 0.07247. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 95.54it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 61, global step: 123] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.88      0.93        49\n",
            "           2       0.88      1.00      0.94        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.96      0.96      0.96       135\n",
            "weighted avg       0.96      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9555555555555556,\n",
            "  \"train_loss\": 0.09760033711791039\n",
            "}\n",
            " 61% 61/100 [00:01<00:01, 38.09it/s]INFO:trainer:start training epoch 62\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 62/100 iter 0: train loss 0.12098. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 62/100 iter 1: train loss 0.00395. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 62, global step: 124] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.96      0.98        49\n",
            "           2       0.96      1.00      0.98        44\n",
            "\n",
            "    accuracy                           0.99       135\n",
            "   macro avg       0.99      0.99      0.99       135\n",
            "weighted avg       0.99      0.99      0.99       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9851851851851852,\n",
            "  \"train_loss\": 0.06246290821582079\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1098.85it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 62, global step: 124] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.14798499643802643,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 42\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_118\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_124\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_124\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_124\n",
            "training epoch 62/100 iter 1: train loss 0.00395. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 96.15it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 62, global step: 125] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.96      0.98        49\n",
            "           2       0.96      1.00      0.98        44\n",
            "\n",
            "    accuracy                           0.99       135\n",
            "   macro avg       0.99      0.99      0.99       135\n",
            "weighted avg       0.99      0.99      0.99       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9851851851851852,\n",
            "  \"train_loss\": 0.06246290821582079\n",
            "}\n",
            "INFO:trainer:start training epoch 63\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 63/100 iter 0: train loss 0.14496. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 63/100 iter 1: train loss 0.18134. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 63, global step: 126] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.87      0.98      0.92        49\n",
            "           2       0.97      0.84      0.90        44\n",
            "\n",
            "    accuracy                           0.94       135\n",
            "   macro avg       0.95      0.94      0.94       135\n",
            "weighted avg       0.95      0.94      0.94       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9407407407407408,\n",
            "  \"train_loss\": 0.1631508320569992\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 753.29it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 63, global step: 126] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.16013021767139435,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 43\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_120\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_126\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_126\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_126\n",
            "training epoch 63/100 iter 1: train loss 0.18134. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 77.97it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 63, global step: 127] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.87      0.98      0.92        49\n",
            "           2       0.97      0.84      0.90        44\n",
            "\n",
            "    accuracy                           0.94       135\n",
            "   macro avg       0.95      0.94      0.94       135\n",
            "weighted avg       0.95      0.94      0.94       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9407407407407408,\n",
            "  \"train_loss\": 0.1631508320569992\n",
            "}\n",
            "INFO:trainer:start training epoch 64\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 64/100 iter 0: train loss 0.15606. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 64/100 iter 1: train loss 0.08927. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 64, global step: 128] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.87      0.98      0.92        49\n",
            "           2       0.97      0.84      0.90        44\n",
            "\n",
            "    accuracy                           0.94       135\n",
            "   macro avg       0.95      0.94      0.94       135\n",
            "weighted avg       0.95      0.94      0.94       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9407407407407408,\n",
            "  \"train_loss\": 0.12266610935330391\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1137.90it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 64, global step: 128] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.14044353365898132,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 44\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_122\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_128\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_128\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_128\n",
            "training epoch 64/100 iter 1: train loss 0.08927. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 97.29it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 64, global step: 129] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.87      0.98      0.92        49\n",
            "           2       0.97      0.84      0.90        44\n",
            "\n",
            "    accuracy                           0.94       135\n",
            "   macro avg       0.95      0.94      0.94       135\n",
            "weighted avg       0.95      0.94      0.94       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9407407407407408,\n",
            "  \"train_loss\": 0.12266610935330391\n",
            "}\n",
            "INFO:trainer:start training epoch 65\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 65/100 iter 0: train loss 0.11829. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 65/100 iter 1: train loss 0.54187. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 65, global step: 130] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.87      0.98      0.92        49\n",
            "           2       0.97      0.84      0.90        44\n",
            "\n",
            "    accuracy                           0.94       135\n",
            "   macro avg       0.95      0.94      0.94       135\n",
            "weighted avg       0.95      0.94      0.94       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9407407407407408,\n",
            "  \"train_loss\": 0.3300800397992134\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1059.70it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 65, global step: 130] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.052710987627506256,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 45\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_124\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_130\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_130\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_130\n",
            "training epoch 65/100 iter 1: train loss 0.54187. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 89.99it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 65, global step: 131] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.87      0.98      0.92        49\n",
            "           2       0.97      0.84      0.90        44\n",
            "\n",
            "    accuracy                           0.94       135\n",
            "   macro avg       0.95      0.94      0.94       135\n",
            "weighted avg       0.95      0.94      0.94       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9407407407407408,\n",
            "  \"train_loss\": 0.3300800397992134\n",
            "}\n",
            " 65% 65/100 [00:01<00:00, 37.89it/s]INFO:trainer:start training epoch 66\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 66/100 iter 0: train loss 0.08188. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 66/100 iter 1: train loss 0.05131. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 66, global step: 132] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.92      0.96        49\n",
            "           2       0.92      1.00      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.06659482792019844\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1045.96it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.62      0.67      0.64        15\n",
            "weighted avg       0.88      0.93      0.90        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 66, global step: 132] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.62      0.67      0.64        15\n",
            "weighted avg       0.88      0.93      0.90        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.06467576324939728,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 46\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_126\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_132\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_132\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_132\n",
            "training epoch 66/100 iter 1: train loss 0.05131. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 86.85it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 66, global step: 133] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.92      0.96        49\n",
            "           2       0.92      1.00      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.06659482792019844\n",
            "}\n",
            "INFO:trainer:start training epoch 67\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 67/100 iter 0: train loss 0.18468. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 67/100 iter 1: train loss 0.00295. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 67, global step: 134] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.76      0.86        49\n",
            "           2       0.79      1.00      0.88        44\n",
            "\n",
            "    accuracy                           0.91       135\n",
            "   macro avg       0.93      0.92      0.91       135\n",
            "weighted avg       0.93      0.91      0.91       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9111111111111111,\n",
            "  \"train_loss\": 0.09381439129356295\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1138.83it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.62      0.67      0.64        15\n",
            "weighted avg       0.88      0.93      0.90        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 67, global step: 134] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.62      0.67      0.64        15\n",
            "weighted avg       0.88      0.93      0.90        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.07361467182636261,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 47\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_128\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_134\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_134\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_134\n",
            "training epoch 67/100 iter 1: train loss 0.00295. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 89.05it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 67, global step: 135] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.76      0.86        49\n",
            "           2       0.79      1.00      0.88        44\n",
            "\n",
            "    accuracy                           0.91       135\n",
            "   macro avg       0.93      0.92      0.91       135\n",
            "weighted avg       0.93      0.91      0.91       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9111111111111111,\n",
            "  \"train_loss\": 0.09381439129356295\n",
            "}\n",
            "INFO:trainer:start training epoch 68\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 68/100 iter 0: train loss 0.21601. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 68/100 iter 1: train loss 0.07353. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 68, global step: 136] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.73      0.85        49\n",
            "           2       0.77      1.00      0.87        44\n",
            "\n",
            "    accuracy                           0.90       135\n",
            "   macro avg       0.92      0.91      0.91       135\n",
            "weighted avg       0.93      0.90      0.90       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9037037037037037,\n",
            "  \"train_loss\": 0.144771009683609\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 881.53it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 68, global step: 136] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.022469455376267433,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 48\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_130\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_136\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_136\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_136\n",
            "training epoch 68/100 iter 1: train loss 0.07353. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 78.15it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 68, global step: 137] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.73      0.85        49\n",
            "           2       0.77      1.00      0.87        44\n",
            "\n",
            "    accuracy                           0.90       135\n",
            "   macro avg       0.92      0.91      0.91       135\n",
            "weighted avg       0.93      0.90      0.90       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9037037037037037,\n",
            "  \"train_loss\": 0.144771009683609\n",
            "}\n",
            "INFO:trainer:start training epoch 69\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 69/100 iter 0: train loss 0.08659. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 69/100 iter 1: train loss 0.10379. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 69, global step: 138] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.88      0.93        49\n",
            "           2       0.88      1.00      0.94        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.96      0.96      0.96       135\n",
            "weighted avg       0.96      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9555555555555556,\n",
            "  \"train_loss\": 0.09519010409712791\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1106.68it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 69, global step: 138] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.0913364365696907,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 49\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_132\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_138\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_138\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_138\n",
            "training epoch 69/100 iter 1: train loss 0.10379. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 92.53it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 69, global step: 139] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.88      0.93        49\n",
            "           2       0.88      1.00      0.94        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.96      0.96      0.96       135\n",
            "weighted avg       0.96      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9555555555555556,\n",
            "  \"train_loss\": 0.09519010409712791\n",
            "}\n",
            " 69% 69/100 [00:01<00:00, 36.95it/s]INFO:trainer:start training epoch 70\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 70/100 iter 0: train loss 0.07154. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 70/100 iter 1: train loss 0.59339. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 70, global step: 140] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.91      0.98      0.94        49\n",
            "           2       0.97      0.89      0.93        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.96      0.96      0.96       135\n",
            "weighted avg       0.96      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9555555555555556,\n",
            "  \"train_loss\": 0.33246513083577156\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 699.87it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.62      0.67      0.64        15\n",
            "weighted avg       0.88      0.93      0.90        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 70, global step: 140] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.62      0.67      0.64        15\n",
            "weighted avg       0.88      0.93      0.90        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.07217507809400558,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 50\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_134\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_140\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_140\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_140\n",
            "training epoch 70/100 iter 1: train loss 0.59339. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 69.20it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 70, global step: 141] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.91      0.98      0.94        49\n",
            "           2       0.97      0.89      0.93        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.96      0.96      0.96       135\n",
            "weighted avg       0.96      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9555555555555556,\n",
            "  \"train_loss\": 0.33246513083577156\n",
            "}\n",
            "INFO:trainer:start training epoch 71\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 71/100 iter 0: train loss 0.21398. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 71/100 iter 1: train loss 0.70921. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 71, global step: 142] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.73      0.85        49\n",
            "           2       0.77      1.00      0.87        44\n",
            "\n",
            "    accuracy                           0.90       135\n",
            "   macro avg       0.92      0.91      0.91       135\n",
            "weighted avg       0.93      0.90      0.90       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9037037037037037,\n",
            "  \"train_loss\": 0.4615924134850502\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1222.12it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.62      0.67      0.64        15\n",
            "weighted avg       0.88      0.93      0.90        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 71, global step: 142] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.62      0.67      0.64        15\n",
            "weighted avg       0.88      0.93      0.90        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.326681524515152,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 51\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_136\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_142\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_142\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_142\n",
            "training epoch 71/100 iter 1: train loss 0.70921. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 94.12it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 71, global step: 143] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.73      0.85        49\n",
            "           2       0.77      1.00      0.87        44\n",
            "\n",
            "    accuracy                           0.90       135\n",
            "   macro avg       0.92      0.91      0.91       135\n",
            "weighted avg       0.93      0.90      0.90       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9037037037037037,\n",
            "  \"train_loss\": 0.4615924134850502\n",
            "}\n",
            "INFO:trainer:start training epoch 72\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 72/100 iter 0: train loss 1.25266. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 72/100 iter 1: train loss 1.64625. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 72, global step: 144] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.08      0.15        49\n",
            "           2       0.49      1.00      0.66        44\n",
            "\n",
            "    accuracy                           0.67       135\n",
            "   macro avg       0.83      0.69      0.60       135\n",
            "weighted avg       0.84      0.67      0.58       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.6666666666666666,\n",
            "  \"train_loss\": 1.4494531750679016\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1057.57it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.62      0.67      0.64        15\n",
            "weighted avg       0.88      0.93      0.90        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 72, global step: 144] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.62      0.67      0.64        15\n",
            "weighted avg       0.88      0.93      0.90        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.15391696989536285,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 52\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_138\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_144\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_144\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_144\n",
            "training epoch 72/100 iter 1: train loss 1.64625. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 91.45it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 72, global step: 145] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.08      0.15        49\n",
            "           2       0.49      1.00      0.66        44\n",
            "\n",
            "    accuracy                           0.67       135\n",
            "   macro avg       0.83      0.69      0.60       135\n",
            "weighted avg       0.84      0.67      0.58       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.6666666666666666,\n",
            "  \"train_loss\": 1.4494531750679016\n",
            "}\n",
            "INFO:trainer:start training epoch 73\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 73/100 iter 0: train loss 0.59144. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 73/100 iter 1: train loss 0.18041. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 73, global step: 146] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.12      0.22        49\n",
            "           2       0.51      1.00      0.67        44\n",
            "\n",
            "    accuracy                           0.68       135\n",
            "   macro avg       0.84      0.71      0.63       135\n",
            "weighted avg       0.84      0.68      0.61       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.6814814814814815,\n",
            "  \"train_loss\": 0.38592227548360825\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1141.31it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 73, global step: 146] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.17083212733268738,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 53\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_140\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_146\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_146\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_146\n",
            "training epoch 73/100 iter 1: train loss 0.18041. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 90.86it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 73, global step: 147] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.12      0.22        49\n",
            "           2       0.51      1.00      0.67        44\n",
            "\n",
            "    accuracy                           0.68       135\n",
            "   macro avg       0.84      0.71      0.63       135\n",
            "weighted avg       0.84      0.68      0.61       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.6814814814814815,\n",
            "  \"train_loss\": 0.38592227548360825\n",
            "}\n",
            " 73% 73/100 [00:01<00:00, 36.55it/s]INFO:trainer:start training epoch 74\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 74/100 iter 0: train loss 0.24720. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 74/100 iter 1: train loss 0.31931. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 74, global step: 148] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.90      0.95        49\n",
            "           2       0.90      1.00      0.95        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.97      0.97      0.96       135\n",
            "weighted avg       0.97      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9629629629629629,\n",
            "  \"train_loss\": 0.28325246274471283\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1164.11it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.17      1.00      0.29         1\n",
            "         2.0       1.00      0.17      0.29         6\n",
            "\n",
            "    accuracy                           0.67        15\n",
            "   macro avg       0.72      0.72      0.52        15\n",
            "weighted avg       0.94      0.67      0.67        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 74, global step: 148] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.17      1.00      0.29         1\n",
            "         2.0       1.00      0.17      0.29         6\n",
            "\n",
            "    accuracy                           0.67        15\n",
            "   macro avg       0.72      0.72      0.52        15\n",
            "weighted avg       0.94      0.67      0.67        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.3693676292896271,\n",
            "  \"dev_accuracy\": 0.6666666666666666,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 54\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_142\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_148\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_148\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_148\n",
            "training epoch 74/100 iter 1: train loss 0.31931. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 100.28it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 74, global step: 149] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.90      0.95        49\n",
            "           2       0.90      1.00      0.95        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.97      0.97      0.96       135\n",
            "weighted avg       0.97      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9629629629629629,\n",
            "  \"train_loss\": 0.28325246274471283\n",
            "}\n",
            "INFO:trainer:start training epoch 75\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 75/100 iter 0: train loss 0.35643. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 75/100 iter 1: train loss 0.13694. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 75, global step: 150] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        42\n",
            "           1       0.53      0.98      0.69        49\n",
            "           2       1.00      0.05      0.09        44\n",
            "\n",
            "    accuracy                           0.68       135\n",
            "   macro avg       0.84      0.68      0.59       135\n",
            "weighted avg       0.82      0.68      0.59       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.6814814814814815,\n",
            "  \"train_loss\": 0.24668531119823456\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1068.34it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.14      1.00      0.25         1\n",
            "         2.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.60        15\n",
            "   macro avg       0.38      0.67      0.42        15\n",
            "weighted avg       0.54      0.60      0.55        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 75, global step: 150] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.14      1.00      0.25         1\n",
            "         2.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.60        15\n",
            "   macro avg       0.38      0.67      0.42        15\n",
            "weighted avg       0.54      0.60      0.55        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.5216925740242004,\n",
            "  \"dev_accuracy\": 0.6,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 55\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_144\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_150\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_150\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_150\n",
            "training epoch 75/100 iter 1: train loss 0.13694. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 97.87it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 75, global step: 151] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        42\n",
            "           1       0.53      0.98      0.69        49\n",
            "           2       1.00      0.05      0.09        44\n",
            "\n",
            "    accuracy                           0.68       135\n",
            "   macro avg       0.84      0.68      0.59       135\n",
            "weighted avg       0.82      0.68      0.59       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.6814814814814815,\n",
            "  \"train_loss\": 0.24668531119823456\n",
            "}\n",
            "INFO:trainer:start training epoch 76\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 76/100 iter 0: train loss 0.43967. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 76/100 iter 1: train loss 0.58065. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 76, global step: 152] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        42\n",
            "           1       0.52      0.98      0.68        49\n",
            "           2       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.67       135\n",
            "   macro avg       0.50      0.66      0.56       135\n",
            "weighted avg       0.49      0.67      0.55       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.6666666666666666,\n",
            "  \"train_loss\": 0.5101569145917892\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1159.61it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.14      1.00      0.25         1\n",
            "         2.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.60        15\n",
            "   macro avg       0.38      0.67      0.42        15\n",
            "weighted avg       0.54      0.60      0.55        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 76, global step: 152] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.14      1.00      0.25         1\n",
            "         2.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.60        15\n",
            "   macro avg       0.38      0.67      0.42        15\n",
            "weighted avg       0.54      0.60      0.55        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.5832525491714478,\n",
            "  \"dev_accuracy\": 0.6,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 56\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_146\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_152\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_152\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_152\n",
            "training epoch 76/100 iter 1: train loss 0.58065. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 95.79it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 76, global step: 153] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        42\n",
            "           1       0.52      0.98      0.68        49\n",
            "           2       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.67       135\n",
            "   macro avg       0.50      0.66      0.56       135\n",
            "weighted avg       0.49      0.67      0.55       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.6666666666666666,\n",
            "  \"train_loss\": 0.5101569145917892\n",
            "}\n",
            "INFO:trainer:start training epoch 77\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 77/100 iter 0: train loss 0.51034. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 77/100 iter 1: train loss 0.00633. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 77, global step: 154] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.53      1.00      0.69        49\n",
            "           2       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.67       135\n",
            "   macro avg       0.51      0.67      0.56       135\n",
            "weighted avg       0.50      0.67      0.56       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.674074074074074,\n",
            "  \"train_loss\": 0.25833302619867027\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1098.56it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.14      1.00      0.25         1\n",
            "         2.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.60        15\n",
            "   macro avg       0.38      0.67      0.42        15\n",
            "weighted avg       0.54      0.60      0.55        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 77, global step: 154] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.14      1.00      0.25         1\n",
            "         2.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.60        15\n",
            "   macro avg       0.38      0.67      0.42        15\n",
            "weighted avg       0.54      0.60      0.55        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.5214027166366577,\n",
            "  \"dev_accuracy\": 0.6,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 57\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_148\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_154\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_154\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_154\n",
            "training epoch 77/100 iter 1: train loss 0.00633. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 95.35it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 77, global step: 155] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.53      1.00      0.69        49\n",
            "           2       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.67       135\n",
            "   macro avg       0.51      0.67      0.56       135\n",
            "weighted avg       0.50      0.67      0.56       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.674074074074074,\n",
            "  \"train_loss\": 0.25833302619867027\n",
            "}\n",
            " 77% 77/100 [00:02<00:00, 37.38it/s]INFO:trainer:start training epoch 78\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 78/100 iter 0: train loss 0.45835. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 78/100 iter 1: train loss 0.02242. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 78, global step: 156] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.53      1.00      0.69        49\n",
            "           2       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.67       135\n",
            "   macro avg       0.51      0.67      0.56       135\n",
            "weighted avg       0.50      0.67      0.56       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.674074074074074,\n",
            "  \"train_loss\": 0.24038752354681492\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1071.89it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.14      1.00      0.25         1\n",
            "         2.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.60        15\n",
            "   macro avg       0.38      0.67      0.42        15\n",
            "weighted avg       0.54      0.60      0.55        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 78, global step: 156] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.14      1.00      0.25         1\n",
            "         2.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.60        15\n",
            "   macro avg       0.38      0.67      0.42        15\n",
            "weighted avg       0.54      0.60      0.55        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.4956020414829254,\n",
            "  \"dev_accuracy\": 0.6,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 58\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_150\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_156\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_156\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_156\n",
            "training epoch 78/100 iter 1: train loss 0.02242. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 80.11it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 78, global step: 157] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.53      1.00      0.69        49\n",
            "           2       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.67       135\n",
            "   macro avg       0.51      0.67      0.56       135\n",
            "weighted avg       0.50      0.67      0.56       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.674074074074074,\n",
            "  \"train_loss\": 0.24038752354681492\n",
            "}\n",
            "INFO:trainer:start training epoch 79\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 79/100 iter 0: train loss 0.42414. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 79/100 iter 1: train loss 0.71944. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 79, global step: 158] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.53      1.00      0.69        49\n",
            "           2       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.67       135\n",
            "   macro avg       0.51      0.67      0.56       135\n",
            "weighted avg       0.50      0.67      0.56       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.674074074074074,\n",
            "  \"train_loss\": 0.5717901289463043\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1158.65it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.14      1.00      0.25         1\n",
            "         2.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.60        15\n",
            "   macro avg       0.38      0.67      0.42        15\n",
            "weighted avg       0.54      0.60      0.55        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 79, global step: 158] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.14      1.00      0.25         1\n",
            "         2.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.60        15\n",
            "   macro avg       0.38      0.67      0.42        15\n",
            "weighted avg       0.54      0.60      0.55        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.4791536331176758,\n",
            "  \"dev_accuracy\": 0.6,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 59\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_152\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_158\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_158\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_158\n",
            "training epoch 79/100 iter 1: train loss 0.71944. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 91.08it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 79, global step: 159] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.53      1.00      0.69        49\n",
            "           2       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.67       135\n",
            "   macro avg       0.51      0.67      0.56       135\n",
            "weighted avg       0.50      0.67      0.56       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.674074074074074,\n",
            "  \"train_loss\": 0.5717901289463043\n",
            "}\n",
            "INFO:trainer:start training epoch 80\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 80/100 iter 0: train loss 0.44098. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 80/100 iter 1: train loss 0.21616. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 80, global step: 160] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.53      1.00      0.69        49\n",
            "           2       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.67       135\n",
            "   macro avg       0.51      0.67      0.56       135\n",
            "weighted avg       0.50      0.67      0.56       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.674074074074074,\n",
            "  \"train_loss\": 0.32857078313827515\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1099.71it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.14      1.00      0.25         1\n",
            "         2.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.60        15\n",
            "   macro avg       0.38      0.67      0.42        15\n",
            "weighted avg       0.54      0.60      0.55        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 80, global step: 160] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.14      1.00      0.25         1\n",
            "         2.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.60        15\n",
            "   macro avg       0.38      0.67      0.42        15\n",
            "weighted avg       0.54      0.60      0.55        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.44528928399086,\n",
            "  \"dev_accuracy\": 0.6,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 60\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_154\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_160\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_160\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_160\n",
            "training epoch 80/100 iter 1: train loss 0.21616. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 86.37it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 80, global step: 161] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.53      1.00      0.69        49\n",
            "           2       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.67       135\n",
            "   macro avg       0.51      0.67      0.56       135\n",
            "weighted avg       0.50      0.67      0.56       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.674074074074074,\n",
            "  \"train_loss\": 0.32857078313827515\n",
            "}\n",
            "INFO:trainer:start training epoch 81\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 81/100 iter 0: train loss 0.40849. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 81/100 iter 1: train loss 0.63510. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 81, global step: 162] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.53      1.00      0.69        49\n",
            "           2       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.67       135\n",
            "   macro avg       0.51      0.67      0.56       135\n",
            "weighted avg       0.50      0.67      0.56       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.674074074074074,\n",
            "  \"train_loss\": 0.5217923372983932\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1011.16it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.14      1.00      0.25         1\n",
            "         2.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.60        15\n",
            "   macro avg       0.38      0.67      0.42        15\n",
            "weighted avg       0.54      0.60      0.55        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 81, global step: 162] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.14      1.00      0.25         1\n",
            "         2.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.60        15\n",
            "   macro avg       0.38      0.67      0.42        15\n",
            "weighted avg       0.54      0.60      0.55        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.39650580286979675,\n",
            "  \"dev_accuracy\": 0.6,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 61\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_156\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_162\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_162\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_162\n",
            "training epoch 81/100 iter 1: train loss 0.63510. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 79.30it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 81, global step: 163] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.53      1.00      0.69        49\n",
            "           2       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.67       135\n",
            "   macro avg       0.51      0.67      0.56       135\n",
            "weighted avg       0.50      0.67      0.56       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.674074074074074,\n",
            "  \"train_loss\": 0.5217923372983932\n",
            "}\n",
            " 81% 81/100 [00:02<00:00, 36.48it/s]INFO:trainer:start training epoch 82\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 82/100 iter 0: train loss 0.38964. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 82/100 iter 1: train loss 0.29949. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 82, global step: 164] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.53      1.00      0.69        49\n",
            "           2       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.67       135\n",
            "   macro avg       0.51      0.67      0.56       135\n",
            "weighted avg       0.50      0.67      0.56       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.674074074074074,\n",
            "  \"train_loss\": 0.34456320106983185\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1014.10it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.20      1.00      0.33         1\n",
            "         2.0       1.00      0.33      0.50         6\n",
            "\n",
            "    accuracy                           0.73        15\n",
            "   macro avg       0.73      0.78      0.61        15\n",
            "weighted avg       0.95      0.73      0.76        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 82, global step: 164] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.20      1.00      0.33         1\n",
            "         2.0       1.00      0.33      0.50         6\n",
            "\n",
            "    accuracy                           0.73        15\n",
            "   macro avg       0.73      0.78      0.61        15\n",
            "weighted avg       0.95      0.73      0.76        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.3316121995449066,\n",
            "  \"dev_accuracy\": 0.7333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 62\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_158\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_164\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_164\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_164\n",
            "training epoch 82/100 iter 1: train loss 0.29949. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 84.86it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 82, global step: 165] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.53      1.00      0.69        49\n",
            "           2       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.67       135\n",
            "   macro avg       0.51      0.67      0.56       135\n",
            "weighted avg       0.50      0.67      0.56       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.674074074074074,\n",
            "  \"train_loss\": 0.34456320106983185\n",
            "}\n",
            "INFO:trainer:start training epoch 83\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 83/100 iter 0: train loss 0.33271. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 83/100 iter 1: train loss 0.28700. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 83, global step: 166] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.65      1.00      0.79        49\n",
            "           2       1.00      0.41      0.58        44\n",
            "\n",
            "    accuracy                           0.81       135\n",
            "   macro avg       0.88      0.80      0.79       135\n",
            "weighted avg       0.87      0.81      0.79       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.8074074074074075,\n",
            "  \"train_loss\": 0.30985575914382935\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1269.08it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 83, global step: 166] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.2659855782985687,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 63\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_160\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_166\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_166\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_166\n",
            "training epoch 83/100 iter 1: train loss 0.28700. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 99.20it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 83, global step: 167] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.65      1.00      0.79        49\n",
            "           2       1.00      0.41      0.58        44\n",
            "\n",
            "    accuracy                           0.81       135\n",
            "   macro avg       0.88      0.80      0.79       135\n",
            "weighted avg       0.87      0.81      0.79       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.8074074074074075,\n",
            "  \"train_loss\": 0.30985575914382935\n",
            "}\n",
            "INFO:trainer:start training epoch 84\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 84/100 iter 0: train loss 0.27319. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 84/100 iter 1: train loss 0.22726. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 84, global step: 168] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.87      0.98      0.92        49\n",
            "           2       0.97      0.84      0.90        44\n",
            "\n",
            "    accuracy                           0.94       135\n",
            "   macro avg       0.95      0.94      0.94       135\n",
            "weighted avg       0.95      0.94      0.94       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9407407407407408,\n",
            "  \"train_loss\": 0.25022468715906143\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1093.12it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 84, global step: 168] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.19809092581272125,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 64\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_162\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_168\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_168\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_168\n",
            "training epoch 84/100 iter 1: train loss 0.22726. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 95.99it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 84, global step: 169] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.87      0.98      0.92        49\n",
            "           2       0.97      0.84      0.90        44\n",
            "\n",
            "    accuracy                           0.94       135\n",
            "   macro avg       0.95      0.94      0.94       135\n",
            "weighted avg       0.95      0.94      0.94       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9407407407407408,\n",
            "  \"train_loss\": 0.25022468715906143\n",
            "}\n",
            "INFO:trainer:start training epoch 85\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 85/100 iter 0: train loss 0.20889. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 85/100 iter 1: train loss 0.30062. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 85, global step: 170] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.96      0.97        49\n",
            "           2       0.96      0.98      0.97        44\n",
            "\n",
            "    accuracy                           0.98       135\n",
            "   macro avg       0.98      0.98      0.98       135\n",
            "weighted avg       0.98      0.98      0.98       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9777777777777777,\n",
            "  \"train_loss\": 0.25475628674030304\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 707.18it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 85, global step: 170] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.13612133264541626,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 65\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_164\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_170\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_170\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_170\n",
            "training epoch 85/100 iter 1: train loss 0.30062. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 71.63it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 85, global step: 171] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.96      0.97        49\n",
            "           2       0.96      0.98      0.97        44\n",
            "\n",
            "    accuracy                           0.98       135\n",
            "   macro avg       0.98      0.98      0.98       135\n",
            "weighted avg       0.98      0.98      0.98       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9777777777777777,\n",
            "  \"train_loss\": 0.25475628674030304\n",
            "}\n",
            " 85% 85/100 [00:02<00:00, 36.44it/s]INFO:trainer:start training epoch 86\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 86/100 iter 0: train loss 0.15477. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 86/100 iter 1: train loss 0.20159. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 86, global step: 172] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.94      0.97        49\n",
            "           2       0.94      1.00      0.97        44\n",
            "\n",
            "    accuracy                           0.98       135\n",
            "   macro avg       0.98      0.98      0.98       135\n",
            "weighted avg       0.98      0.98      0.98       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9777777777777777,\n",
            "  \"train_loss\": 0.17817775905132294\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1085.48it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 86, global step: 172] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.08615224808454514,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 66\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_166\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_172\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_172\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_172\n",
            "training epoch 86/100 iter 1: train loss 0.20159. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 95.61it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 86, global step: 173] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.94      0.97        49\n",
            "           2       0.94      1.00      0.97        44\n",
            "\n",
            "    accuracy                           0.98       135\n",
            "   macro avg       0.98      0.98      0.98       135\n",
            "weighted avg       0.98      0.98      0.98       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9777777777777777,\n",
            "  \"train_loss\": 0.17817775905132294\n",
            "}\n",
            "INFO:trainer:start training epoch 87\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 87/100 iter 0: train loss 0.11942. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 87/100 iter 1: train loss 0.02591. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 87, global step: 174] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.92      0.96        49\n",
            "           2       0.92      1.00      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.07266259752213955\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 932.90it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 87, global step: 174] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.05107669159770012,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 67\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_168\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_174\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_174\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_174\n",
            "training epoch 87/100 iter 1: train loss 0.02591. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 89.80it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 87, global step: 175] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.92      0.96        49\n",
            "           2       0.92      1.00      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.07266259752213955\n",
            "}\n",
            "INFO:trainer:start training epoch 88\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 88/100 iter 0: train loss 0.09441. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 88/100 iter 1: train loss 0.02581. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 88, global step: 176] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.92      0.96        49\n",
            "           2       0.92      1.00      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.06011043302714825\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1031.30it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 88, global step: 176] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.031929101794958115,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 68\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_170\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_176\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_176\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_176\n",
            "training epoch 88/100 iter 1: train loss 0.02581. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 95.67it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 88, global step: 177] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.92      0.96        49\n",
            "           2       0.92      1.00      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.06011043302714825\n",
            "}\n",
            "INFO:trainer:start training epoch 89\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 89/100 iter 0: train loss 0.08395. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 89/100 iter 1: train loss 0.03789. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 89, global step: 178] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.90      0.95        49\n",
            "           2       0.90      1.00      0.95        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.97      0.97      0.96       135\n",
            "weighted avg       0.97      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9629629629629629,\n",
            "  \"train_loss\": 0.060921257361769676\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1004.62it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 89, global step: 178] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.021025430411100388,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 69\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_172\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_178\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_178\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_178\n",
            "training epoch 89/100 iter 1: train loss 0.03789. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 94.12it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 89, global step: 179] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.90      0.95        49\n",
            "           2       0.90      1.00      0.95        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.97      0.97      0.96       135\n",
            "weighted avg       0.97      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9629629629629629,\n",
            "  \"train_loss\": 0.060921257361769676\n",
            "}\n",
            " 89% 89/100 [00:02<00:00, 37.02it/s]INFO:trainer:start training epoch 90\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 90/100 iter 0: train loss 0.08097. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 90/100 iter 1: train loss 0.00859. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 90, global step: 180] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.92      0.96        49\n",
            "           2       0.92      1.00      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.044780781492590904\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1201.12it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 90, global step: 180] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.01678742654621601,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 70\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_174\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_180\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_180\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_180\n",
            "\n",
            "training epoch 90/100 iter 1: train loss 0.00859. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 17.38it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 90, global step: 181] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.92      0.96        49\n",
            "           2       0.92      1.00      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.044780781492590904\n",
            "}\n",
            "INFO:trainer:start training epoch 91\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 91/100 iter 0: train loss 0.07019. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 91/100 iter 1: train loss 0.07861. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 91, global step: 182] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.92      0.96        49\n",
            "           2       0.92      1.00      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.07440236210823059\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1101.73it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 91, global step: 182] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.01401067990809679,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 71\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_176\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_182\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_182\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_182\n",
            "training epoch 91/100 iter 1: train loss 0.07861. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 98.15it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 91, global step: 183] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.92      0.96        49\n",
            "           2       0.92      1.00      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.07440236210823059\n",
            "}\n",
            "INFO:trainer:start training epoch 92\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 92/100 iter 0: train loss 0.07122. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 92/100 iter 1: train loss 0.00039. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 92, global step: 184] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.92      0.96        49\n",
            "           2       0.92      1.00      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.03580277063883841\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1123.57it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 92, global step: 184] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.011595573276281357,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 72\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_178\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_184\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_184\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_184\n",
            "training epoch 92/100 iter 1: train loss 0.00039. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 98.21it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 92, global step: 185] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.92      0.96        49\n",
            "           2       0.92      1.00      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.03580277063883841\n",
            "}\n",
            "INFO:trainer:start training epoch 93\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 93/100 iter 0: train loss 0.07100. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 93/100 iter 1: train loss 0.02902. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 93, global step: 186] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.92      0.96        49\n",
            "           2       0.92      1.00      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.0500065041705966\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 713.56it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 93, global step: 186] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.012846453115344048,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 73\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_180\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_186\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_186\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_186\n",
            "training epoch 93/100 iter 1: train loss 0.02902. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 75.65it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 93, global step: 187] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.92      0.96        49\n",
            "           2       0.92      1.00      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.0500065041705966\n",
            "}\n",
            " 93% 93/100 [00:02<00:00, 29.54it/s]INFO:trainer:start training epoch 94\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 94/100 iter 0: train loss 0.06491. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 94/100 iter 1: train loss 0.00385. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 94, global step: 188] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.92      0.96        49\n",
            "           2       0.92      1.00      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.03438043443020433\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1142.55it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 94, global step: 188] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.01647263951599598,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 74\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_182\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_188\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_188\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_188\n",
            "training epoch 94/100 iter 1: train loss 0.00385. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 100.74it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 94, global step: 189] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.92      0.96        49\n",
            "           2       0.92      1.00      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.03438043443020433\n",
            "}\n",
            "INFO:trainer:start training epoch 95\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 95/100 iter 0: train loss 0.05862. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 95/100 iter 1: train loss 0.00658. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 95, global step: 190] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.94      0.97        49\n",
            "           2       0.94      1.00      0.97        44\n",
            "\n",
            "    accuracy                           0.98       135\n",
            "   macro avg       0.98      0.98      0.98       135\n",
            "weighted avg       0.98      0.98      0.98       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9777777777777777,\n",
            "  \"train_loss\": 0.032601096434518695\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1081.28it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 95, global step: 190] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.02630339004099369,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 75\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_184\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_190\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_190\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_190\n",
            "training epoch 95/100 iter 1: train loss 0.00658. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 94.52it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 95, global step: 191] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      0.94      0.97        49\n",
            "           2       0.94      1.00      0.97        44\n",
            "\n",
            "    accuracy                           0.98       135\n",
            "   macro avg       0.98      0.98      0.98       135\n",
            "weighted avg       0.98      0.98      0.98       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9777777777777777,\n",
            "  \"train_loss\": 0.032601096434518695\n",
            "}\n",
            "INFO:trainer:start training epoch 96\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 96/100 iter 0: train loss 0.05424. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 96/100 iter 1: train loss 0.00060. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 96, global step: 192] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.96      0.97        49\n",
            "           2       0.96      0.98      0.97        44\n",
            "\n",
            "    accuracy                           0.98       135\n",
            "   macro avg       0.98      0.98      0.98       135\n",
            "weighted avg       0.98      0.98      0.98       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9777777777777777,\n",
            "  \"train_loss\": 0.027419168094638735\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 944.88it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 96, global step: 192] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.039526861160993576,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 76\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_186\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_192\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_192\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_192\n",
            "training epoch 96/100 iter 1: train loss 0.00060. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 91.55it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 96, global step: 193] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.96      0.97        49\n",
            "           2       0.96      0.98      0.97        44\n",
            "\n",
            "    accuracy                           0.98       135\n",
            "   macro avg       0.98      0.98      0.98       135\n",
            "weighted avg       0.98      0.98      0.98       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9777777777777777,\n",
            "  \"train_loss\": 0.027419168094638735\n",
            "}\n",
            "INFO:trainer:start training epoch 97\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 97/100 iter 0: train loss 0.05834. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 97/100 iter 1: train loss 0.00011. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 97, global step: 194] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.98      0.98        49\n",
            "           2       0.98      0.98      0.98        44\n",
            "\n",
            "    accuracy                           0.99       135\n",
            "   macro avg       0.99      0.99      0.99       135\n",
            "weighted avg       0.99      0.99      0.99       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9851851851851852,\n",
            "  \"train_loss\": 0.029224998066638364\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1189.54it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 97, global step: 194] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.0329570434987545,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 77\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_188\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_194\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_194\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_194\n",
            "training epoch 97/100 iter 1: train loss 0.00011. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 97.20it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 97, global step: 195] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.98      0.98        49\n",
            "           2       0.98      0.98      0.98        44\n",
            "\n",
            "    accuracy                           0.99       135\n",
            "   macro avg       0.99      0.99      0.99       135\n",
            "weighted avg       0.99      0.99      0.99       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9851851851851852,\n",
            "  \"train_loss\": 0.029224998066638364\n",
            "}\n",
            " 97% 97/100 [00:02<00:00, 32.01it/s]INFO:trainer:start training epoch 98\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 98/100 iter 0: train loss 0.05590. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 98/100 iter 1: train loss 0.00015. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 98, global step: 196] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.98      0.98        49\n",
            "           2       0.98      0.98      0.98        44\n",
            "\n",
            "    accuracy                           0.99       135\n",
            "   macro avg       0.99      0.99      0.99       135\n",
            "weighted avg       0.99      0.99      0.99       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9851851851851852,\n",
            "  \"train_loss\": 0.028025886043906212\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1037.68it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 98, global step: 196] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.019922500476241112,\n",
            "  \"dev_accuracy\": 1.0,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 78\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_190\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_196\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_196\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_196\n",
            "training epoch 98/100 iter 1: train loss 0.00015. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 97.05it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 98, global step: 197] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.98      0.98        49\n",
            "           2       0.98      0.98      0.98        44\n",
            "\n",
            "    accuracy                           0.99       135\n",
            "   macro avg       0.99      0.99      0.99       135\n",
            "weighted avg       0.99      0.99      0.99       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9851851851851852,\n",
            "  \"train_loss\": 0.028025886043906212\n",
            "}\n",
            "INFO:trainer:start training epoch 99\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 99/100 iter 0: train loss 0.04677. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 99/100 iter 1: train loss 0.22786. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 99, global step: 198] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.94      0.96        49\n",
            "           2       0.93      0.98      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.1373151857405901\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1173.23it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 99, global step: 198] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.07185829430818558,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 79\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_192\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_198\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_198\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_198\n",
            "training epoch 99/100 iter 1: train loss 0.22786. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 99.95it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 99, global step: 199] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.98      0.94      0.96        49\n",
            "           2       0.93      0.98      0.96        44\n",
            "\n",
            "    accuracy                           0.97       135\n",
            "   macro avg       0.97      0.97      0.97       135\n",
            "weighted avg       0.97      0.97      0.97       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9703703703703703,\n",
            "  \"train_loss\": 0.1373151857405901\n",
            "}\n",
            "INFO:trainer:start training epoch 100\n",
            "INFO:trainer:training using device=cpu\n",
            "INFO:trainer:\n",
            "*************hyperparam_dict**********\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_epochs\": 100,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"train_batch_size\": 130,\n",
            "  \"no_improve_count\": 0,\n",
            "  \"device\": \"cpu\",\n",
            "  \"patience\": 200,\n",
            "  \"save_path\": \"tmp/mlp_iris\",\n",
            "  \"eval_on\": \"accuracy\",\n",
            "  \"eval_every\": 2,\n",
            "  \"use_wandb\": false,\n",
            "  \"loss_fn\": \"ce\",\n",
            "  \"keep_ck_num\": 3,\n",
            "  \"lr\": 0.03\n",
            "}\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 100/100 iter 0: train loss 0.07947. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "training epoch 100/100 iter 1: train loss 0.00594. lr 3.000000e-02:   0% 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
            "*****************[epoch: 100, global step: 200] eval training set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.91      0.98      0.94        49\n",
            "           2       0.97      0.89      0.93        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.96      0.96      0.96       135\n",
            "weighted avg       0.96      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9555555555555556,\n",
            "  \"train_loss\": 0.0427097559440881\n",
            "}\n",
            "\n",
            "\n",
            "evaluating: 100% 1/1 [00:00<00:00, 1141.62it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:\n",
            "*****************[epoch: 100, global step: 200] eval development set based on eval_every=2***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       0.50      1.00      0.67         1\n",
            "         2.0       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.83      0.94      0.86        15\n",
            "weighted avg       0.97      0.93      0.94        15\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"dev_loss\": 0.2333042025566101,\n",
            "  \"dev_accuracy\": 0.9333333333333333,\n",
            "  \"dev_best_score_for_accuracy\": 1.0\n",
            "}\n",
            "INFO:trainer:  no_improve_count: 80\n",
            "INFO:trainer:  patience: 200\n",
            "INFO:trainer:   Check 3 checkpoints already saved\n",
            "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
            "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_194\n",
            "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_200\n",
            "INFO:mlp:save model to path: tmp/mlp_iris/ck_200\n",
            "INFO:trainer:save model to path: tmp/mlp_iris/ck_200\n",
            "training epoch 100/100 iter 1: train loss 0.00594. lr 3.000000e-02: 100% 2/2 [00:00<00:00, 99.75it/s]\n",
            "INFO:trainer:\n",
            "*****************[epoch: 100, global step: 201] eval training set at end of epoch***************\n",
            "INFO:trainer:              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       0.91      0.98      0.94        49\n",
            "           2       0.97      0.89      0.93        44\n",
            "\n",
            "    accuracy                           0.96       135\n",
            "   macro avg       0.96      0.96      0.96       135\n",
            "weighted avg       0.96      0.96      0.96       135\n",
            "\n",
            "INFO:trainer:{\n",
            "  \"train_accuracy_score\": 0.9555555555555556,\n",
            "  \"train_loss\": 0.0427097559440881\n",
            "}\n",
            "100% 100/100 [00:02<00:00, 36.34it/s]\n",
            "load from saved path\n",
            "*******************eval on train set of iris*******************\n",
            "evaluating: 100% 3/3 [00:00<00:00, 463.95it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00        42\n",
            "         1.0       1.00      0.96      0.98        49\n",
            "         2.0       0.96      1.00      0.98        44\n",
            "\n",
            "    accuracy                           0.99       135\n",
            "   macro avg       0.99      0.99      0.99       135\n",
            "weighted avg       0.99      0.99      0.99       135\n",
            "\n",
            "{'loss': 0.11197520047426224, 'accuracy': 0.9851851851851852, 'preds': [2, 0, 2, 1, 1, 2, 0, 0, 1, 2, 1, 1, 1, 0, 1, 2, 0, 0, 1, 0, 1, 2, 0, 2, 0, 1, 2, 2, 2, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 2, 0, 1, 2, 1, 2, 2, 2, 1, 0, 0, 1, 2, 0, 1, 1, 0, 1, 2, 0, 1, 1, 0, 0, 1, 1, 0, 2, 2, 2, 2, 1, 0, 0, 1, 2, 0, 0, 0, 2, 2, 1, 2, 0, 1, 0, 2, 2, 2, 1, 2, 0, 0, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 1, 0, 1, 0, 2, 2, 1, 2, 0, 2, 1, 0, 0, 2, 2, 1, 1, 1, 0, 0, 2], 'groundtruths': [2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0]}\n",
            "*************eval on test set of iris*******************\n",
            "evaluating: 100% 1/1 [00:00<00:00, 563.90it/s]\n",
            "INFO:mlp:              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "{'loss': 0.057833291590213776, 'accuracy': 1.0, 'preds': [1, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2], 'groundtruths': [1.0, 2.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}