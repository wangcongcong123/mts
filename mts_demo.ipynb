{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "mts_demo.ipynb",
   "provenance": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyP6wKwBysN81OlIcoAENHLn",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/wangcongcong123/mts/blob/master/mts_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFjcXWWQenNq",
    "colab_type": "text"
   },
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wLyW8N91el41",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "outputId": "801b50dd-7974-415d-fd49-5d2d684881f7"
   },
   "source": [
    "!git clone https://github.com/wangcongcong123/mts.git\n",
    "%cd mts\n",
    "!pip install -r requirements.txt"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Cloning into 'mts'...\n",
      "remote: Enumerating objects: 69, done.\u001b[K\n",
      "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
      "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
      "remote: Total 69 (delta 19), reused 55 (delta 10), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (69/69), done.\n",
      "/content/mts\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.22.2.post1)\n",
      "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.6.0+cu101)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.18.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.0.5)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.17.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.34.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.15.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (2.23.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (3.12.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (49.2.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.31.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (3.2.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 5)) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 5)) (2.8.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 3)) (1.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->-r requirements.txt (line 3)) (3.1.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVsuvbQFfxf-",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "## Run\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "unA6DTSffFlv",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "032f30c6-3833-4f17-8c28-f40fce4b6192"
   },
   "source": [
    "from dataset import CSVDataset\n",
    "from mlp import MLP\n",
    "from trainer import Trainer\n",
    "\n",
    "# here we use the test set that is simply sampled 10% from the original iris dataset.\n",
    "train_path = \"./data/iris/train.csv\"\n",
    "test_path = \"./data/iris/test.csv\"\n",
    "\n",
    "save_path = \"tmp/mlp_iris\"  # where the model's checkpoints are saved to\n",
    "\n",
    "numeric_feature_names = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "# load train data and dev data\n",
    "train_data = CSVDataset(train_path, numeric_feature_names=numeric_feature_names, label_name=\"target\")\n",
    "dev_data = CSVDataset(test_path, numeric_feature_names=numeric_feature_names, label_name=\"target\")\n",
    "# initialize a model\n",
    "model = MLP(len(numeric_feature_names), train_data.num_label, hidden_units=[64, 32, 16], device=\"cpu\")\n",
    "# initialize a trainer\n",
    "trainer = Trainer(train_data, model,\n",
    "                  dev_data=dev_data,\n",
    "                  eval_on=\"accuracy\",\n",
    "                  loss_fn=\"ce\",\n",
    "                  eval_every=2,\n",
    "                  device=\"cpu\",\n",
    "                  save_path=save_path,\n",
    "                  train_epochs=100,\n",
    "                  train_batch_size=128)\n",
    "# start training\n",
    "trainer.train()\n",
    "\n",
    "#### load model from the save path\n",
    "# this can be run separately from training\n",
    "print(\"load from saved path\")\n",
    "model = MLP.load_model(save_path)\n",
    "print(\"*******************eval on train set of iris*******************\")\n",
    "print(model.evaluate(train_data, device=\"cpu\"))\n",
    "print(\"*************eval on test set of iris*******************\")\n",
    "print(model.evaluate(dev_data, device=\"cpu\"))"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 48/100 iter 0: train loss 0.08888. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 48/100 iter 1: train loss 0.15540. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 48, global step: 96] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.12214075028896332\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 203.99it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 48, global step: 96] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.05829806998372078,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 38\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_90\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_96\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_96\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_96\n",
      "training epoch 48/100 iter 1: train loss 0.15540. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 22.69it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 48, global step: 97] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.12214075028896332\n",
      "}\n",
      " 48%|████▊     | 48/100 [00:05<00:06,  8.52it/s]INFO:trainer:start training epoch 49\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 49/100 iter 0: train loss 0.07423. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 49/100 iter 1: train loss 0.05179. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 49, global step: 98] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.96      0.98        45\n",
      "           2       0.96      1.00      0.98        43\n",
      "\n",
      "    accuracy                           0.99       135\n",
      "   macro avg       0.99      0.99      0.98       135\n",
      "weighted avg       0.99      0.99      0.99       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9851851851851852,\n",
      "  \"train_loss\": 0.0630064606666565\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 393.31it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 49, global step: 98] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.166957825422287,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 39\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_92\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_98\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_98\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_98\n",
      "training epoch 49/100 iter 1: train loss 0.05179. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 22.70it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 49, global step: 99] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.96      0.98        45\n",
      "           2       0.96      1.00      0.98        43\n",
      "\n",
      "    accuracy                           0.99       135\n",
      "   macro avg       0.99      0.99      0.98       135\n",
      "weighted avg       0.99      0.99      0.99       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9851851851851852,\n",
      "  \"train_loss\": 0.0630064606666565\n",
      "}\n",
      " 49%|████▉     | 49/100 [00:05<00:05,  8.62it/s]INFO:trainer:start training epoch 50\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 50/100 iter 0: train loss 0.12767. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 50/100 iter 1: train loss 0.03742. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 50, global step: 100] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.85      0.98      0.91        45\n",
      "           2       0.97      0.81      0.89        43\n",
      "\n",
      "    accuracy                           0.93       135\n",
      "   macro avg       0.94      0.93      0.93       135\n",
      "weighted avg       0.94      0.93      0.93       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9333333333333333,\n",
      "  \"train_loss\": 0.08254524506628513\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 356.63it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 50, global step: 100] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.13538524508476257,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 40\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_94\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_100\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_100\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_100\n",
      "training epoch 50/100 iter 1: train loss 0.03742. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 22.43it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 50, global step: 101] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.85      0.98      0.91        45\n",
      "           2       0.97      0.81      0.89        43\n",
      "\n",
      "    accuracy                           0.93       135\n",
      "   macro avg       0.94      0.93      0.93       135\n",
      "weighted avg       0.94      0.93      0.93       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9333333333333333,\n",
      "  \"train_loss\": 0.08254524506628513\n",
      "}\n",
      " 50%|█████     | 50/100 [00:06<00:05,  8.56it/s]INFO:trainer:start training epoch 51\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 51/100 iter 0: train loss 0.10892. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 51/100 iter 1: train loss 0.01360. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 51, global step: 102] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.86      0.98      0.92        45\n",
      "           2       0.97      0.84      0.90        43\n",
      "\n",
      "    accuracy                           0.94       135\n",
      "   macro avg       0.95      0.94      0.94       135\n",
      "weighted avg       0.95      0.94      0.94       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9407407407407408,\n",
      "  \"train_loss\": 0.06126096099615097\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 351.40it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 51, global step: 102] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.048174042254686356,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 41\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_96\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_102\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_102\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_102\n",
      "training epoch 51/100 iter 1: train loss 0.01360. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 20.48it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 51, global step: 103] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.86      0.98      0.92        45\n",
      "           2       0.97      0.84      0.90        43\n",
      "\n",
      "    accuracy                           0.94       135\n",
      "   macro avg       0.95      0.94      0.94       135\n",
      "weighted avg       0.95      0.94      0.94       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9407407407407408,\n",
      "  \"train_loss\": 0.06126096099615097\n",
      "}\n",
      " 51%|█████     | 51/100 [00:06<00:05,  8.32it/s]INFO:trainer:start training epoch 52\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 52/100 iter 0: train loss 0.07312. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 52/100 iter 1: train loss 0.01459. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 52, global step: 104] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.96      0.98        45\n",
      "           2       0.96      1.00      0.98        43\n",
      "\n",
      "    accuracy                           0.99       135\n",
      "   macro avg       0.99      0.99      0.98       135\n",
      "weighted avg       0.99      0.99      0.99       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9851851851851852,\n",
      "  \"train_loss\": 0.04385364940389991\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 279.73it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 52, global step: 104] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.03511713072657585,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 42\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_98\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_104\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_104\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_104\n",
      "training epoch 52/100 iter 1: train loss 0.01459. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 20.61it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 52, global step: 105] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.96      0.98        45\n",
      "           2       0.96      1.00      0.98        43\n",
      "\n",
      "    accuracy                           0.99       135\n",
      "   macro avg       0.99      0.99      0.98       135\n",
      "weighted avg       0.99      0.99      0.99       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9851851851851852,\n",
      "  \"train_loss\": 0.04385364940389991\n",
      "}\n",
      " 52%|█████▏    | 52/100 [00:06<00:05,  8.21it/s]INFO:trainer:start training epoch 53\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 53/100 iter 0: train loss 0.09825. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 53/100 iter 1: train loss 0.02612. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 53, global step: 106] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.89      0.94        45\n",
      "           2       0.90      1.00      0.95        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.97      0.96      0.96       135\n",
      "weighted avg       0.97      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9629629629629629,\n",
      "  \"train_loss\": 0.062185075134038925\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 427.38it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 53, global step: 106] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.03427494317293167,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 43\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_100\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_106\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_106\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_106\n",
      "training epoch 53/100 iter 1: train loss 0.02612. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 24.85it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 53, global step: 107] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.89      0.94        45\n",
      "           2       0.90      1.00      0.95        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.97      0.96      0.96       135\n",
      "weighted avg       0.97      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9629629629629629,\n",
      "  \"train_loss\": 0.062185075134038925\n",
      "}\n",
      " 53%|█████▎    | 53/100 [00:06<00:05,  8.56it/s]INFO:trainer:start training epoch 54\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 54/100 iter 0: train loss 0.10378. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 54/100 iter 1: train loss 0.01590. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 54, global step: 108] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.89      0.94        45\n",
      "           2       0.90      1.00      0.95        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.97      0.96      0.96       135\n",
      "weighted avg       0.97      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9629629629629629,\n",
      "  \"train_loss\": 0.059837957844138145\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 477.22it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 54, global step: 108] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.03330297768115997,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 44\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_102\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_108\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_108\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_108\n",
      "training epoch 54/100 iter 1: train loss 0.01590. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 29.71it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 54, global step: 109] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.89      0.94        45\n",
      "           2       0.90      1.00      0.95        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.97      0.96      0.96       135\n",
      "weighted avg       0.97      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9629629629629629,\n",
      "  \"train_loss\": 0.059837957844138145\n",
      "}\n",
      "INFO:trainer:start training epoch 55\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 55/100 iter 0: train loss 0.07629. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 55/100 iter 1: train loss 0.04463. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 55, global step: 110] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.06045904569327831\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 241.32it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 55, global step: 110] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.04571544751524925,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 45\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_104\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_110\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_110\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_110\n",
      "training epoch 55/100 iter 1: train loss 0.04463. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 27.18it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 55, global step: 111] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.06045904569327831\n",
      "}\n",
      " 55%|█████▌    | 55/100 [00:06<00:04,  9.13it/s]INFO:trainer:start training epoch 56\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 56/100 iter 0: train loss 0.06067. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 56/100 iter 1: train loss 0.17803. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 56, global step: 112] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.96      0.98        45\n",
      "           2       0.96      1.00      0.98        43\n",
      "\n",
      "    accuracy                           0.99       135\n",
      "   macro avg       0.99      0.99      0.98       135\n",
      "weighted avg       0.99      0.99      0.99       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9851851851851852,\n",
      "  \"train_loss\": 0.1193469762802124\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 462.95it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 56, global step: 112] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.0840110331773758,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 46\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_106\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_112\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_112\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_112\n",
      "training epoch 56/100 iter 1: train loss 0.17803. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 23.37it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 56, global step: 113] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.96      0.98        45\n",
      "           2       0.96      1.00      0.98        43\n",
      "\n",
      "    accuracy                           0.99       135\n",
      "   macro avg       0.99      0.99      0.98       135\n",
      "weighted avg       0.99      0.99      0.99       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9851851851851852,\n",
      "  \"train_loss\": 0.1193469762802124\n",
      "}\n",
      " 56%|█████▌    | 56/100 [00:06<00:04,  9.02it/s]INFO:trainer:start training epoch 57\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 57/100 iter 0: train loss 0.07760. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 57/100 iter 1: train loss 0.03108. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 57, global step: 114] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.92      0.98      0.95        45\n",
      "           2       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.96       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9629629629629629,\n",
      "  \"train_loss\": 0.054339153692126274\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 412.10it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 57, global step: 114] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.1808127462863922,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 47\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_108\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_114\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_114\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_114\n",
      "training epoch 57/100 iter 1: train loss 0.03108. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 25.27it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 57, global step: 115] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.92      0.98      0.95        45\n",
      "           2       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.96       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9629629629629629,\n",
      "  \"train_loss\": 0.054339153692126274\n",
      "}\n",
      " 57%|█████▋    | 57/100 [00:06<00:04,  8.82it/s]INFO:trainer:start training epoch 58\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 58/100 iter 0: train loss 0.12924. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 58/100 iter 1: train loss 0.19503. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 58, global step: 116] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.85      0.98      0.91        45\n",
      "           2       0.97      0.81      0.89        43\n",
      "\n",
      "    accuracy                           0.93       135\n",
      "   macro avg       0.94      0.93      0.93       135\n",
      "weighted avg       0.94      0.93      0.93       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9333333333333333,\n",
      "  \"train_loss\": 0.1621333360671997\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 406.90it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.71      1.00      0.83         5\n",
      "         2.0       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.90      0.90      0.89        15\n",
      "weighted avg       0.90      0.87      0.87        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 58, global step: 116] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.71      1.00      0.83         5\n",
      "         2.0       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.90      0.90      0.89        15\n",
      "weighted avg       0.90      0.87      0.87        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.2693398892879486,\n",
      "  \"dev_accuracy\": 0.8666666666666667,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 48\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_110\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_116\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_116\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_116\n",
      "training epoch 58/100 iter 1: train loss 0.19503. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 25.44it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 58, global step: 117] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.85      0.98      0.91        45\n",
      "           2       0.97      0.81      0.89        43\n",
      "\n",
      "    accuracy                           0.93       135\n",
      "   macro avg       0.94      0.93      0.93       135\n",
      "weighted avg       0.94      0.93      0.93       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9333333333333333,\n",
      "  \"train_loss\": 0.1621333360671997\n",
      "}\n",
      " 58%|█████▊    | 58/100 [00:06<00:04,  9.13it/s]INFO:trainer:start training epoch 59\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 59/100 iter 0: train loss 0.18380. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 59/100 iter 1: train loss 0.23843. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 59, global step: 118] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.82      1.00      0.90        45\n",
      "           2       1.00      0.77      0.87        43\n",
      "\n",
      "    accuracy                           0.93       135\n",
      "   macro avg       0.94      0.92      0.92       135\n",
      "weighted avg       0.94      0.93      0.92       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9259259259259259,\n",
      "  \"train_loss\": 0.21111513674259186\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 417.14it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 59, global step: 118] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.05012976750731468,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 49\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_112\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_118\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_118\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_118\n",
      "training epoch 59/100 iter 1: train loss 0.23843. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 20.99it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 59, global step: 119] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.82      1.00      0.90        45\n",
      "           2       1.00      0.77      0.87        43\n",
      "\n",
      "    accuracy                           0.93       135\n",
      "   macro avg       0.94      0.92      0.92       135\n",
      "weighted avg       0.94      0.93      0.92       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9259259259259259,\n",
      "  \"train_loss\": 0.21111513674259186\n",
      "}\n",
      " 59%|█████▉    | 59/100 [00:07<00:04,  8.85it/s]INFO:trainer:start training epoch 60\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 60/100 iter 0: train loss 0.06745. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 60/100 iter 1: train loss 0.00603. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 60, global step: 120] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.98      0.96      0.97        45\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.03674045787192881\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 452.66it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      0.80      0.89         5\n",
      "         2.0       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.96      0.93      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 60, global step: 120] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      0.80      0.89         5\n",
      "         2.0       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.96      0.93      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.10968270152807236,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 50\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_114\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_120\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_120\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_120\n",
      "training epoch 60/100 iter 1: train loss 0.00603. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 25.45it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 60, global step: 121] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.98      0.96      0.97        45\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.03674045787192881\n",
      "}\n",
      " 60%|██████    | 60/100 [00:07<00:04,  9.10it/s]INFO:trainer:start training epoch 61\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 61/100 iter 0: train loss 0.23969. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 61/100 iter 1: train loss 0.13049. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 61, global step: 122] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.71      0.83        45\n",
      "           2       0.77      1.00      0.87        43\n",
      "\n",
      "    accuracy                           0.90       135\n",
      "   macro avg       0.92      0.90      0.90       135\n",
      "weighted avg       0.93      0.90      0.90       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9037037037037037,\n",
      "  \"train_loss\": 0.18508726358413696\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 396.40it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      0.80      0.89         5\n",
      "         2.0       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.96      0.93      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 61, global step: 122] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      0.80      0.89         5\n",
      "         2.0       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.96      0.93      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.09962061047554016,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 51\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_116\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_122\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_122\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_122\n",
      "training epoch 61/100 iter 1: train loss 0.13049. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 25.15it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 61, global step: 123] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.71      0.83        45\n",
      "           2       0.77      1.00      0.87        43\n",
      "\n",
      "    accuracy                           0.90       135\n",
      "   macro avg       0.92      0.90      0.90       135\n",
      "weighted avg       0.93      0.90      0.90       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9037037037037037,\n",
      "  \"train_loss\": 0.18508726358413696\n",
      "}\n",
      " 61%|██████    | 61/100 [00:07<00:04,  9.30it/s]INFO:trainer:start training epoch 62\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 62/100 iter 0: train loss 0.23206. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 62/100 iter 1: train loss 0.01746. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 62, global step: 124] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.76      0.86        45\n",
      "           2       0.80      1.00      0.89        43\n",
      "\n",
      "    accuracy                           0.92       135\n",
      "   macro avg       0.93      0.92      0.92       135\n",
      "weighted avg       0.94      0.92      0.92       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9185185185185185,\n",
      "  \"train_loss\": 0.1247625220566988\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 468.11it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 62, global step: 124] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.030293472111225128,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 52\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_118\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_124\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_124\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_124\n",
      "training epoch 62/100 iter 1: train loss 0.01746. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 27.71it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 62, global step: 125] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.76      0.86        45\n",
      "           2       0.80      1.00      0.89        43\n",
      "\n",
      "    accuracy                           0.92       135\n",
      "   macro avg       0.93      0.92      0.92       135\n",
      "weighted avg       0.94      0.92      0.92       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9185185185185185,\n",
      "  \"train_loss\": 0.1247625220566988\n",
      "}\n",
      "INFO:trainer:start training epoch 63\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 63/100 iter 0: train loss 0.06902. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 63/100 iter 1: train loss 0.18532. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 63, global step: 126] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.98      0.93      0.95        45\n",
      "           2       0.93      0.98      0.95        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.12717199325561523\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 480.61it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 63, global step: 126] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.07739625871181488,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 53\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_120\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_126\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_126\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_126\n",
      "training epoch 63/100 iter 1: train loss 0.18532. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 26.49it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 63, global step: 127] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.98      0.93      0.95        45\n",
      "           2       0.93      0.98      0.95        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.12717199325561523\n",
      "}\n",
      " 63%|██████▎   | 63/100 [00:07<00:03,  9.61it/s]INFO:trainer:start training epoch 64\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 64/100 iter 0: train loss 0.07267. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 64/100 iter 1: train loss 0.04446. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 64, global step: 128] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.92      0.98      0.95        45\n",
      "           2       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.96       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9629629629629629,\n",
      "  \"train_loss\": 0.05856228433549404\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 483.05it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 64, global step: 128] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.03200254961848259,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 54\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_122\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_128\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_128\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_128\n",
      "training epoch 64/100 iter 1: train loss 0.04446. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 28.20it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 64, global step: 129] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.92      0.98      0.95        45\n",
      "           2       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.96       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9629629629629629,\n",
      "  \"train_loss\": 0.05856228433549404\n",
      "}\n",
      "INFO:trainer:start training epoch 65\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 65/100 iter 0: train loss 0.04511. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 65/100 iter 1: train loss 0.55012. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 65, global step: 130] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.93      0.97        45\n",
      "           2       0.93      1.00      0.97        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.29761706478893757\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 405.01it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 65, global step: 130] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.03444628044962883,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 55\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_124\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_130\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_130\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_130\n",
      "training epoch 65/100 iter 1: train loss 0.55012. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 28.10it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 65, global step: 131] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.93      0.97        45\n",
      "           2       0.93      1.00      0.97        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.29761706478893757\n",
      "}\n",
      " 65%|██████▌   | 65/100 [00:07<00:03,  9.88it/s]INFO:trainer:start training epoch 66\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 66/100 iter 0: train loss 0.06822. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 66/100 iter 1: train loss 0.04851. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 66, global step: 132] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.96      0.98        45\n",
      "           2       0.96      1.00      0.98        43\n",
      "\n",
      "    accuracy                           0.99       135\n",
      "   macro avg       0.99      0.99      0.98       135\n",
      "weighted avg       0.99      0.99      0.99       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9851851851851852,\n",
      "  \"train_loss\": 0.05836242623627186\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 408.13it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 66, global step: 132] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.07149327546358109,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 56\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_126\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_132\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_132\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_132\n",
      "training epoch 66/100 iter 1: train loss 0.04851. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 27.38it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 66, global step: 133] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.96      0.98        45\n",
      "           2       0.96      1.00      0.98        43\n",
      "\n",
      "    accuracy                           0.99       135\n",
      "   macro avg       0.99      0.99      0.98       135\n",
      "weighted avg       0.99      0.99      0.99       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9851851851851852,\n",
      "  \"train_loss\": 0.05836242623627186\n",
      "}\n",
      "INFO:trainer:start training epoch 67\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 67/100 iter 0: train loss 0.07275. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 67/100 iter 1: train loss 0.02359. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 67, global step: 134] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.94      0.98      0.96        45\n",
      "           2       0.98      0.93      0.95        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.04817239847034216\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 373.96it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 67, global step: 134] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.05225510895252228,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 57\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_128\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_134\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_134\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_134\n",
      "training epoch 67/100 iter 1: train loss 0.02359. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 27.26it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 67, global step: 135] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.94      0.98      0.96        45\n",
      "           2       0.98      0.93      0.95        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.04817239847034216\n",
      "}\n",
      " 67%|██████▋   | 67/100 [00:07<00:03, 10.05it/s]INFO:trainer:start training epoch 68\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 68/100 iter 0: train loss 0.06293. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 68/100 iter 1: train loss 0.08124. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 68, global step: 136] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.98      0.96      0.97        45\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.07208088040351868\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 403.53it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 68, global step: 136] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.027203094214200974,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 58\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_130\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_136\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_136\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_136\n",
      "training epoch 68/100 iter 1: train loss 0.08124. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 24.78it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 68, global step: 137] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.98      0.96      0.97        45\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.07208088040351868\n",
      "}\n",
      "INFO:trainer:start training epoch 69\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 69/100 iter 0: train loss 0.07746. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 69/100 iter 1: train loss 0.25908. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 69, global step: 138] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.16826745122671127\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 499.08it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 69, global step: 138] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.028094951063394547,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 59\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_132\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_138\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_138\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_138\n",
      "training epoch 69/100 iter 1: train loss 0.25908. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 24.09it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 69, global step: 139] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.16826745122671127\n",
      "}\n",
      " 69%|██████▉   | 69/100 [00:08<00:03,  9.83it/s]INFO:trainer:start training epoch 70\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 70/100 iter 0: train loss 0.08117. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 70/100 iter 1: train loss 0.00185. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 70, global step: 140] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.04151059396099299\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 461.98it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 70, global step: 140] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.09732065349817276,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 60\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_134\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_140\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_140\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_140\n",
      "training epoch 70/100 iter 1: train loss 0.00185. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 28.06it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 70, global step: 141] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.04151059396099299\n",
      "}\n",
      "INFO:trainer:start training epoch 71\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 71/100 iter 0: train loss 0.08560. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 71/100 iter 1: train loss 0.02609. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 71, global step: 142] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.92      0.98      0.95        45\n",
      "           2       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.96       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9629629629629629,\n",
      "  \"train_loss\": 0.05584329552948475\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 556.27it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 71, global step: 142] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.1553887277841568,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 61\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_136\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_142\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_142\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_142\n",
      "training epoch 71/100 iter 1: train loss 0.02609. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 25.62it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 71, global step: 143] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.92      0.98      0.95        45\n",
      "           2       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.96       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9629629629629629,\n",
      "  \"train_loss\": 0.05584329552948475\n",
      "}\n",
      " 71%|███████   | 71/100 [00:08<00:02,  9.97it/s]INFO:trainer:start training epoch 72\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 72/100 iter 0: train loss 0.11812. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 72/100 iter 1: train loss 0.03103. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 72, global step: 144] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.85      0.98      0.91        45\n",
      "           2       0.97      0.81      0.89        43\n",
      "\n",
      "    accuracy                           0.93       135\n",
      "   macro avg       0.94      0.93      0.93       135\n",
      "weighted avg       0.94      0.93      0.93       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9333333333333333,\n",
      "  \"train_loss\": 0.07457462605088949\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 468.74it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 72, global step: 144] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.0670902207493782,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 62\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_138\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_144\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_144\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_144\n",
      "training epoch 72/100 iter 1: train loss 0.03103. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 25.01it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 72, global step: 145] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.85      0.98      0.91        45\n",
      "           2       0.97      0.81      0.89        43\n",
      "\n",
      "    accuracy                           0.93       135\n",
      "   macro avg       0.94      0.93      0.93       135\n",
      "weighted avg       0.94      0.93      0.93       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9333333333333333,\n",
      "  \"train_loss\": 0.07457462605088949\n",
      "}\n",
      "INFO:trainer:start training epoch 73\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 73/100 iter 0: train loss 0.06429. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 73/100 iter 1: train loss 0.08279. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 73, global step: 146] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.96      0.98      0.97        45\n",
      "           2       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.07353637740015984\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 477.28it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 73, global step: 146] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.029268808662891388,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 63\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_140\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_146\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_146\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_146\n",
      "training epoch 73/100 iter 1: train loss 0.08279. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 26.02it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 73, global step: 147] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.96      0.98      0.97        45\n",
      "           2       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.07353637740015984\n",
      "}\n",
      " 73%|███████▎  | 73/100 [00:08<00:02,  9.88it/s]INFO:trainer:start training epoch 74\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 74/100 iter 0: train loss 0.07867. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 74/100 iter 1: train loss 0.65815. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 74, global step: 148] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.87      0.93        45\n",
      "           2       0.88      1.00      0.93        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.95       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9555555555555556,\n",
      "  \"train_loss\": 0.36841094493865967\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 513.63it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 74, global step: 148] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.03167439624667168,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 64\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_142\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_148\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_148\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_148\n",
      "training epoch 74/100 iter 1: train loss 0.65815. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 27.54it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 74, global step: 149] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.87      0.93        45\n",
      "           2       0.88      1.00      0.93        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.95       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9555555555555556,\n",
      "  \"train_loss\": 0.36841094493865967\n",
      "}\n",
      "INFO:trainer:start training epoch 75\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 75/100 iter 0: train loss 0.07045. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 75/100 iter 1: train loss 0.00933. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 75, global step: 150] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.03988840663805604\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 329.15it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.71      1.00      0.83         5\n",
      "         2.0       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.90      0.90      0.89        15\n",
      "weighted avg       0.90      0.87      0.87        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 75, global step: 150] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.71      1.00      0.83         5\n",
      "         2.0       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.90      0.90      0.89        15\n",
      "weighted avg       0.90      0.87      0.87        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.35916778445243835,\n",
      "  \"dev_accuracy\": 0.8666666666666667,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 65\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_144\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_150\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_150\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_150\n",
      "training epoch 75/100 iter 1: train loss 0.00933. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 26.48it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 75, global step: 151] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.03988840663805604\n",
      "}\n",
      " 75%|███████▌  | 75/100 [00:08<00:02, 10.01it/s]INFO:trainer:start training epoch 76\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 76/100 iter 0: train loss 0.24745. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 76/100 iter 1: train loss 0.28272. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 76, global step: 152] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.78      1.00      0.87        45\n",
      "           2       1.00      0.70      0.82        43\n",
      "\n",
      "    accuracy                           0.90       135\n",
      "   macro avg       0.93      0.90      0.90       135\n",
      "weighted avg       0.93      0.90      0.90       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9037037037037037,\n",
      "  \"train_loss\": 0.2650870904326439\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 324.24it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 76, global step: 152] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.12032441794872284,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 66\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_146\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_152\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_152\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_152\n",
      "training epoch 76/100 iter 1: train loss 0.28272. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 23.63it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 76, global step: 153] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.78      1.00      0.87        45\n",
      "           2       1.00      0.70      0.82        43\n",
      "\n",
      "    accuracy                           0.90       135\n",
      "   macro avg       0.93      0.90      0.90       135\n",
      "weighted avg       0.93      0.90      0.90       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9037037037037037,\n",
      "  \"train_loss\": 0.2650870904326439\n",
      "}\n",
      "INFO:trainer:start training epoch 77\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 77/100 iter 0: train loss 0.09919. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 77/100 iter 1: train loss 0.01831. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 77, global step: 154] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.86      0.98      0.92        45\n",
      "           2       0.97      0.84      0.90        43\n",
      "\n",
      "    accuracy                           0.94       135\n",
      "   macro avg       0.95      0.94      0.94       135\n",
      "weighted avg       0.95      0.94      0.94       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9407407407407408,\n",
      "  \"train_loss\": 0.058750479482114315\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 515.52it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 77, global step: 154] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.06848781555891037,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 67\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_148\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_154\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_154\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_154\n",
      "training epoch 77/100 iter 1: train loss 0.01831. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 27.36it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 77, global step: 155] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.86      0.98      0.92        45\n",
      "           2       0.97      0.84      0.90        43\n",
      "\n",
      "    accuracy                           0.94       135\n",
      "   macro avg       0.95      0.94      0.94       135\n",
      "weighted avg       0.95      0.94      0.94       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9407407407407408,\n",
      "  \"train_loss\": 0.058750479482114315\n",
      "}\n",
      " 77%|███████▋  | 77/100 [00:08<00:02,  9.91it/s]INFO:trainer:start training epoch 78\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 78/100 iter 0: train loss 0.16647. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 78/100 iter 1: train loss 0.14641. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 78, global step: 156] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.82      0.90        45\n",
      "           2       0.84      1.00      0.91        43\n",
      "\n",
      "    accuracy                           0.94       135\n",
      "   macro avg       0.95      0.94      0.94       135\n",
      "weighted avg       0.95      0.94      0.94       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9407407407407408,\n",
      "  \"train_loss\": 0.15644323080778122\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 494.90it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      0.80      0.89         5\n",
      "         2.0       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.96      0.93      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 78, global step: 156] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      0.80      0.89         5\n",
      "         2.0       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.96      0.93      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.13436287641525269,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 68\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_150\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_156\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_156\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_156\n",
      "training epoch 78/100 iter 1: train loss 0.14641. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 27.17it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 78, global step: 157] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.82      0.90        45\n",
      "           2       0.84      1.00      0.91        43\n",
      "\n",
      "    accuracy                           0.94       135\n",
      "   macro avg       0.95      0.94      0.94       135\n",
      "weighted avg       0.95      0.94      0.94       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9407407407407408,\n",
      "  \"train_loss\": 0.15644323080778122\n",
      "}\n",
      "INFO:trainer:start training epoch 79\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 79/100 iter 0: train loss 0.24084. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 79/100 iter 1: train loss 0.00712. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 79, global step: 158] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.71      0.83        45\n",
      "           2       0.77      1.00      0.87        43\n",
      "\n",
      "    accuracy                           0.90       135\n",
      "   macro avg       0.92      0.90      0.90       135\n",
      "weighted avg       0.93      0.90      0.90       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9037037037037037,\n",
      "  \"train_loss\": 0.12398012145422399\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 472.23it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 79, global step: 158] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.035735294222831726,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 69\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_152\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_158\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_158\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_158\n",
      "training epoch 79/100 iter 1: train loss 0.00712. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 26.92it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 79, global step: 159] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.71      0.83        45\n",
      "           2       0.77      1.00      0.87        43\n",
      "\n",
      "    accuracy                           0.90       135\n",
      "   macro avg       0.92      0.90      0.90       135\n",
      "weighted avg       0.93      0.90      0.90       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9037037037037037,\n",
      "  \"train_loss\": 0.12398012145422399\n",
      "}\n",
      " 79%|███████▉  | 79/100 [00:09<00:02, 10.04it/s]INFO:trainer:start training epoch 80\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 80/100 iter 0: train loss 0.10570. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 80/100 iter 1: train loss 0.01439. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 80, global step: 160] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.87      0.93        45\n",
      "           2       0.88      1.00      0.93        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.95       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9555555555555556,\n",
      "  \"train_loss\": 0.06004729028791189\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 360.71it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 80, global step: 160] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.0709758996963501,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 70\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_154\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_160\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_160\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_160\n",
      "training epoch 80/100 iter 1: train loss 0.01439. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 22.66it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 80, global step: 161] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.87      0.93        45\n",
      "           2       0.88      1.00      0.93        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.95       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9555555555555556,\n",
      "  \"train_loss\": 0.06004729028791189\n",
      "}\n",
      "INFO:trainer:start training epoch 81\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 81/100 iter 0: train loss 0.07025. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 81/100 iter 1: train loss 0.09499. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 81, global step: 162] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.96      0.98      0.97        45\n",
      "           2       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.0826227106153965\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 164.03it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 81, global step: 162] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.11786936223506927,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 71\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_156\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_162\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_162\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_162\n",
      "training epoch 81/100 iter 1: train loss 0.09499. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 24.30it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 81, global step: 163] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.96      0.98      0.97        45\n",
      "           2       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.0826227106153965\n",
      "}\n",
      " 81%|████████  | 81/100 [00:09<00:01,  9.73it/s]INFO:trainer:start training epoch 82\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 82/100 iter 0: train loss 0.09654. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 82/100 iter 1: train loss 0.01204. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 82, global step: 164] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.90      0.98      0.94        45\n",
      "           2       0.97      0.88      0.93        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.95      0.95       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9555555555555556,\n",
      "  \"train_loss\": 0.054287747479975224\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 247.69it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 82, global step: 164] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.05925071984529495,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 72\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_158\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_164\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_164\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_164\n",
      "training epoch 82/100 iter 1: train loss 0.01204. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 23.82it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 82, global step: 165] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.90      0.98      0.94        45\n",
      "           2       0.97      0.88      0.93        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.95      0.95       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9555555555555556,\n",
      "  \"train_loss\": 0.054287747479975224\n",
      "}\n",
      " 82%|████████▏ | 82/100 [00:09<00:01,  9.17it/s]INFO:trainer:start training epoch 83\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 83/100 iter 0: train loss 0.05379. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 83/100 iter 1: train loss 0.33876. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 83, global step: 166] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.96      0.96      0.96        45\n",
      "           2       0.95      0.95      0.95        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.19627650454640388\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 352.49it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 83, global step: 166] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.0586213655769825,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 73\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_160\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_166\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_166\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_166\n",
      "training epoch 83/100 iter 1: train loss 0.33876. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 23.60it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 83, global step: 167] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.96      0.96      0.96        45\n",
      "           2       0.95      0.95      0.95        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.19627650454640388\n",
      "}\n",
      " 83%|████████▎ | 83/100 [00:09<00:01,  9.23it/s]INFO:trainer:start training epoch 84\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 84/100 iter 0: train loss 0.06879. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 84/100 iter 1: train loss 0.01952. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 84, global step: 168] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.98      0.96      0.97        45\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.04415159206837416\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 441.60it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 84, global step: 168] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.08974502235651016,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 74\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_162\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_168\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_168\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_168\n",
      "training epoch 84/100 iter 1: train loss 0.01952. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 20.03it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 84, global step: 169] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.98      0.96      0.97        45\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.04415159206837416\n",
      "}\n",
      " 84%|████████▍ | 84/100 [00:09<00:01,  8.89it/s]INFO:trainer:start training epoch 85\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 85/100 iter 0: train loss 0.07739. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 85/100 iter 1: train loss 0.07094. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 85, global step: 170] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.94      0.98      0.96        45\n",
      "           2       0.98      0.93      0.95        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.07416799664497375\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 436.13it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 85, global step: 170] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.059353552758693695,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 75\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_164\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_170\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_170\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_170\n",
      "training epoch 85/100 iter 1: train loss 0.07094. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 29.05it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 85, global step: 171] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.94      0.98      0.96        45\n",
      "           2       0.98      0.93      0.95        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.07416799664497375\n",
      "}\n",
      "INFO:trainer:start training epoch 86\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 86/100 iter 0: train loss 0.06861. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 86/100 iter 1: train loss 0.01473. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 86, global step: 172] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.96      0.96      0.96        45\n",
      "           2       0.95      0.95      0.95        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.0416729673743248\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 479.40it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 86, global step: 172] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.03300617262721062,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 76\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_166\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_172\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_172\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_172\n",
      "training epoch 86/100 iter 1: train loss 0.01473. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 29.46it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 86, global step: 173] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.96      0.96      0.96        45\n",
      "           2       0.95      0.95      0.95        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.0416729673743248\n",
      "}\n",
      " 86%|████████▌ | 86/100 [00:09<00:01,  9.46it/s]INFO:trainer:start training epoch 87\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 87/100 iter 0: train loss 0.07438. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 87/100 iter 1: train loss 0.01856. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 87, global step: 174] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.046469253487885\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 492.29it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 87, global step: 174] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.02867688052356243,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 77\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_168\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_174\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_174\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_174\n",
      "training epoch 87/100 iter 1: train loss 0.01856. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 29.52it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 87, global step: 175] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.046469253487885\n",
      "}\n",
      "INFO:trainer:start training epoch 88\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 88/100 iter 0: train loss 0.08466. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 88/100 iter 1: train loss 0.00986. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 88, global step: 176] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.047259807121008635\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 423.84it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 88, global step: 176] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.028578052297234535,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 78\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_170\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_176\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_176\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_176\n",
      "training epoch 88/100 iter 1: train loss 0.00986. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 27.01it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 88, global step: 177] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.047259807121008635\n",
      "}\n",
      " 88%|████████▊ | 88/100 [00:10<00:01,  9.78it/s]INFO:trainer:start training epoch 89\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 89/100 iter 0: train loss 0.06818. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 89/100 iter 1: train loss 0.10176. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 89, global step: 178] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.93      0.97        45\n",
      "           2       0.93      1.00      0.97        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.08496740087866783\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 465.57it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 89, global step: 178] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.06610479950904846,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 79\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_172\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_178\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_178\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_178\n",
      "training epoch 89/100 iter 1: train loss 0.10176. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 26.41it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 89, global step: 179] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.93      0.97        45\n",
      "           2       0.93      1.00      0.97        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.08496740087866783\n",
      "}\n",
      "INFO:trainer:start training epoch 90\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 90/100 iter 0: train loss 0.06832. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 90/100 iter 1: train loss 0.04121. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 90, global step: 180] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.96      0.98      0.97        45\n",
      "           2       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.05476710759103298\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 416.97it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 90, global step: 180] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.15251752734184265,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 80\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_174\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_180\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_180\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_180\n",
      "training epoch 90/100 iter 1: train loss 0.04121. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 26.09it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 90, global step: 181] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.96      0.98      0.97        45\n",
      "           2       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.05476710759103298\n",
      "}\n",
      " 90%|█████████ | 90/100 [00:10<00:01,  9.77it/s]INFO:trainer:start training epoch 91\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 91/100 iter 0: train loss 0.11810. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 91/100 iter 1: train loss 0.01490. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 91, global step: 182] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.86      0.98      0.92        45\n",
      "           2       0.97      0.84      0.90        43\n",
      "\n",
      "    accuracy                           0.94       135\n",
      "   macro avg       0.95      0.94      0.94       135\n",
      "weighted avg       0.95      0.94      0.94       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9407407407407408,\n",
      "  \"train_loss\": 0.06650059344246984\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 368.76it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 91, global step: 182] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.08596692234277725,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 81\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_176\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_182\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_182\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_182\n",
      "\n",
      "training epoch 91/100 iter 1: train loss 0.01490. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 18.44it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 91, global step: 183] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.86      0.98      0.92        45\n",
      "           2       0.97      0.84      0.90        43\n",
      "\n",
      "    accuracy                           0.94       135\n",
      "   macro avg       0.95      0.94      0.94       135\n",
      "weighted avg       0.95      0.94      0.94       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9407407407407408,\n",
      "  \"train_loss\": 0.06650059344246984\n",
      "}\n",
      " 91%|█████████ | 91/100 [00:10<00:01,  8.87it/s]INFO:trainer:start training epoch 92\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 92/100 iter 0: train loss 0.07938. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 92/100 iter 1: train loss 0.00058. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 92, global step: 184] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.92      0.98      0.95        45\n",
      "           2       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.96       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9629629629629629,\n",
      "  \"train_loss\": 0.03998115690774284\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 333.28it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 92, global step: 184] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.026600431650877,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 82\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_178\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_184\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_184\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_184\n",
      "training epoch 92/100 iter 1: train loss 0.00058. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 21.28it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 92, global step: 185] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.92      0.98      0.95        45\n",
      "           2       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.96       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9629629629629629,\n",
      "  \"train_loss\": 0.03998115690774284\n",
      "}\n",
      " 92%|█████████▏| 92/100 [00:10<00:00,  8.68it/s]INFO:trainer:start training epoch 93\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 93/100 iter 0: train loss 0.06301. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 93/100 iter 1: train loss 0.02836. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 93, global step: 186] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.93      0.97        45\n",
      "           2       0.93      1.00      0.97        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.045685093849897385\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 423.11it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 93, global step: 186] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.020153259858489037,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 83\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_180\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_186\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_186\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_186\n",
      "training epoch 93/100 iter 1: train loss 0.02836. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 23.04it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 93, global step: 187] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.93      0.97        45\n",
      "           2       0.93      1.00      0.97        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.045685093849897385\n",
      "}\n",
      " 93%|█████████▎| 93/100 [00:10<00:00,  8.66it/s]INFO:trainer:start training epoch 94\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 94/100 iter 0: train loss 0.09810. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 94/100 iter 1: train loss 0.01278. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 94, global step: 188] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.89      0.94        45\n",
      "           2       0.90      1.00      0.95        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.97      0.96      0.96       135\n",
      "weighted avg       0.97      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9629629629629629,\n",
      "  \"train_loss\": 0.055443577002733946\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 291.49it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 94, global step: 188] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.023419542238116264,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 84\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_182\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_188\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_188\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_188\n",
      "training epoch 94/100 iter 1: train loss 0.01278. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 22.16it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 94, global step: 189] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.89      0.94        45\n",
      "           2       0.90      1.00      0.95        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.97      0.96      0.96       135\n",
      "weighted avg       0.97      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9629629629629629,\n",
      "  \"train_loss\": 0.055443577002733946\n",
      "}\n",
      " 94%|█████████▍| 94/100 [00:10<00:00,  8.66it/s]INFO:trainer:start training epoch 95\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 95/100 iter 0: train loss 0.11809. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 95/100 iter 1: train loss 0.01754. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 95, global step: 190] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.87      0.93        45\n",
      "           2       0.88      1.00      0.93        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.95       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9555555555555556,\n",
      "  \"train_loss\": 0.06781291123479605\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 450.90it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 95, global step: 190] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.016932878643274307,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 85\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_184\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_190\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_190\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_190\n",
      "training epoch 95/100 iter 1: train loss 0.01754. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 20.49it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 95, global step: 191] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.87      0.93        45\n",
      "           2       0.88      1.00      0.93        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.95       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9555555555555556,\n",
      "  \"train_loss\": 0.06781291123479605\n",
      "}\n",
      " 95%|█████████▌| 95/100 [00:10<00:00,  8.36it/s]INFO:trainer:start training epoch 96\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 96/100 iter 0: train loss 0.08511. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 96/100 iter 1: train loss 0.00617. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 96, global step: 192] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.0456417768727988\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 457.94it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 96, global step: 192] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.04458592087030411,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 86\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_186\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_192\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_192\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_192\n",
      "training epoch 96/100 iter 1: train loss 0.00617. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 22.54it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 96, global step: 193] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.0456417768727988\n",
      "}\n",
      " 96%|█████████▌| 96/100 [00:10<00:00,  8.43it/s]INFO:trainer:start training epoch 97\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 97/100 iter 0: train loss 0.06235. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 97/100 iter 1: train loss 0.00042. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 97, global step: 194] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.96      0.98      0.97        45\n",
      "           2       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.03138200051034801\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 403.34it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 97, global step: 194] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.11348500847816467,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 87\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_188\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_194\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_194\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_194\n",
      "training epoch 97/100 iter 1: train loss 0.00042. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 24.53it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 97, global step: 195] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.96      0.98      0.97        45\n",
      "           2       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9777777777777777,\n",
      "  \"train_loss\": 0.03138200051034801\n",
      "}\n",
      " 97%|█████████▋| 97/100 [00:11<00:00,  8.65it/s]INFO:trainer:start training epoch 98\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 98/100 iter 0: train loss 0.09361. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 98/100 iter 1: train loss 0.01894. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 98, global step: 196] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.86      0.98      0.92        45\n",
      "           2       0.97      0.84      0.90        43\n",
      "\n",
      "    accuracy                           0.94       135\n",
      "   macro avg       0.95      0.94      0.94       135\n",
      "weighted avg       0.95      0.94      0.94       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9407407407407408,\n",
      "  \"train_loss\": 0.056273569352924824\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 337.60it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 98, global step: 196] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       0.83      1.00      0.91         5\n",
      "         2.0       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.95      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.0817108005285263,\n",
      "  \"dev_accuracy\": 0.9333333333333333,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 88\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_190\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_196\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_196\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_196\n",
      "training epoch 98/100 iter 1: train loss 0.01894. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 25.51it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 98, global step: 197] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.86      0.98      0.92        45\n",
      "           2       0.97      0.84      0.90        43\n",
      "\n",
      "    accuracy                           0.94       135\n",
      "   macro avg       0.95      0.94      0.94       135\n",
      "weighted avg       0.95      0.94      0.94       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9407407407407408,\n",
      "  \"train_loss\": 0.056273569352924824\n",
      "}\n",
      " 98%|█████████▊| 98/100 [00:11<00:00,  8.90it/s]INFO:trainer:start training epoch 99\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 99/100 iter 0: train loss 0.07238. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 99/100 iter 1: train loss 0.04412. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 99, global step: 198] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.92      0.98      0.95        45\n",
      "           2       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.96       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9629629629629629,\n",
      "  \"train_loss\": 0.058247895911335945\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 397.38it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 99, global step: 198] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.01877336949110031,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 89\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_192\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_198\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_198\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_198\n",
      "training epoch 99/100 iter 1: train loss 0.04412. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 25.49it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 99, global step: 199] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       0.92      0.98      0.95        45\n",
      "           2       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.96      0.96      0.96       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9629629629629629,\n",
      "  \"train_loss\": 0.058247895911335945\n",
      "}\n",
      " 99%|█████████▉| 99/100 [00:11<00:00,  9.10it/s]INFO:trainer:start training epoch 100\n",
      "INFO:trainer:training using device=cpu\n",
      "INFO:trainer:\n",
      "*************hyperparam_dict**********\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_epochs\": 100,\n",
      "  \"eval_batch_size\": 64,\n",
      "  \"train_batch_size\": 128,\n",
      "  \"no_improve_count\": 0,\n",
      "  \"device\": \"cpu\",\n",
      "  \"patience\": 200,\n",
      "  \"save_path\": \"tmp/mlp_iris\",\n",
      "  \"eval_on\": \"accuracy\",\n",
      "  \"eval_every\": 2,\n",
      "  \"use_wandb\": false,\n",
      "  \"loss_fn\": \"ce\",\n",
      "  \"keep_ck_num\": 3,\n",
      "  \"lr\": 0.01\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 100/100 iter 0: train loss 0.06686. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "training epoch 100/100 iter 1: train loss 0.04135. lr 1.000000e-02:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[AINFO:trainer:\n",
      "*****************[epoch: 100, global step: 200] eval training set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.05410497449338436\n",
      "}\n",
      "\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 413.80it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:\n",
      "*****************[epoch: 100, global step: 200] eval development set based on eval_every=2***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"dev_loss\": 0.01551814004778862,\n",
      "  \"dev_accuracy\": 1.0,\n",
      "  \"dev_best_score_for_accuracy\": 1.0\n",
      "}\n",
      "INFO:trainer:  no_improve_count: 90\n",
      "INFO:trainer:  patience: 200\n",
      "INFO:trainer:   Check 3 checkpoints already saved\n",
      "INFO:trainer:   There are more than keep_ck_num as specified, then remove the oldest saved checkpoint\n",
      "INFO:trainer:  Remove checkpoint tmp/mlp_iris/ck_194\n",
      "INFO:trainer:  Save checkpoint to tmp/mlp_iris/ck_200\n",
      "INFO:mlp:save model to path: tmp/mlp_iris/ck_200\n",
      "INFO:trainer:save model to path: tmp/mlp_iris/ck_200\n",
      "training epoch 100/100 iter 1: train loss 0.04135. lr 1.000000e-02: 100%|██████████| 2/2 [00:00<00:00, 25.03it/s]\n",
      "INFO:trainer:\n",
      "*****************[epoch: 100, global step: 201] eval training set at end of epoch***************\n",
      "INFO:trainer:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        47\n",
      "           1       1.00      0.91      0.95        45\n",
      "           2       0.91      1.00      0.96        43\n",
      "\n",
      "    accuracy                           0.97       135\n",
      "   macro avg       0.97      0.97      0.97       135\n",
      "weighted avg       0.97      0.97      0.97       135\n",
      "\n",
      "INFO:trainer:{\n",
      "  \"train_accuracy_score\": 0.9703703703703703,\n",
      "  \"train_loss\": 0.05410497449338436\n",
      "}\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.77it/s]\n",
      "evaluating: 100%|██████████| 3/3 [00:00<00:00, 266.51it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        47\n",
      "         1.0       1.00      0.93      0.97        45\n",
      "         2.0       0.93      1.00      0.97        43\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "evaluating: 100%|██████████| 1/1 [00:00<00:00, 500.04it/s]\n",
      "INFO:mlp:              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "load from saved path\n",
      "*******************eval on train set of iris*******************\n",
      "{'loss': 0.29136406381924945, 'accuracy': 0.9777777777777777, 'preds': [2, 2, 1, 2, 1, 2, 0, 2, 1, 0, 2, 1, 2, 0, 1, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 2, 0, 2, 2, 0, 0, 2, 0, 2, 1, 0, 1, 0, 2, 2, 1, 2, 1, 2, 0, 1, 2, 2, 2, 1, 0, 1, 1, 2, 0, 0, 2, 2, 1, 1, 0, 0, 0, 1, 1, 2, 1, 2, 0, 1, 0, 1, 0, 1, 0, 2, 0, 2, 2, 1, 2, 2, 2, 0, 1, 0, 1, 1, 2, 1, 0, 2, 2, 1, 0, 2, 1, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 2, 0, 2, 2, 2, 1, 1, 1, 0, 2, 2, 1, 0, 2, 2, 0], 'groundtruths': [2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0]}\n",
      "*************eval on test set of iris*******************\n",
      "{'loss': 0.34086042642593384, 'accuracy': 1.0, 'preds': [2, 1, 0, 2, 2, 1, 2, 2, 1, 2, 0, 1, 0, 1, 2], 'groundtruths': [2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0]}\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TJOb28oOfKr9",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}